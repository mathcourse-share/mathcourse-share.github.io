
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mathcourse-share.github.io/AI/CS231n/CS231n_notes/">
      
      
        <link rel="prev" href="../../%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">
      
      
        <link rel="next" href="../Image%20Classification-Data-driven%20Approach%2C%20k-Nearest%20Neighbor%2C%20train_val_test%20splits/">
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>Computer Vision - 数学分享站</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 32C28.7 32 0 60.7 0 96v320c0 35.3 28.7 64 64 64h224V368c0-26.5 21.5-48 48-48h112V96c0-35.3-28.7-64-64-64zm384 320H336c-8.8 0-16 7.2-16 16v112l32-32 64-64z"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96m0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32m32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16m16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M480 32c0-12.9-7.8-24.6-19.8-29.6S434.5.2 425.3 9.3L381.7 53c-48 48-113.1 75-181 75H64c-35.3 0-64 28.7-64 64v96c0 35.3 28.7 64 64 64v128c0 17.7 14.3 32 32 32h64c17.7 0 32-14.3 32-32V352h8.7c67.9 0 133 27 181 75l43.6 43.6c9.2 9.2 22.9 11.9 34.9 6.9s19.8-16.6 19.8-29.6V300.3c18.6-8.8 32-32.5 32-60.4s-13.4-51.6-32-60.4zm-64 76.7v262.6C357.2 317.8 280.5 288 200.7 288H192v-96h8.7c79.8 0 156.5-29.8 215.3-83.3"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7l233.4-233.3c12.5-12.5 32.8-12.5 45.3 0z"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-86.2-346.7c7.9-22.3 29.1-37.3 52.8-37.3h58.3c34.9 0 63.1 28.3 63.1 63.1 0 22.6-12.1 43.5-31.7 54.8L280 264.4c-.2 13-10.9 23.6-24 23.6-13.3 0-24-10.7-24-24v-13.5c0-8.6 4.6-16.5 12.1-20.8l44.3-25.4c4.7-2.7 7.6-7.7 7.6-13.1 0-8.4-6.8-15.1-15.1-15.1h-58.3c-3.4 0-6.4 2.1-7.5 5.3l-.4 1.2c-4.4 12.5-18.2 19-30.6 14.6s-19-18.2-14.6-30.6l.4-1.2zM224 352a32 32 0 1 1 64 0 32 32 0 1 1-64 0"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 32c14.2 0 27.3 7.5 34.5 19.8l216 368c7.3 12.4 7.3 27.7.2 40.1S486.3 480 472 480H40c-14.3 0-27.6-7.7-34.7-20.1s-7-27.8.2-40.1l216-368C228.7 39.5 241.8 32 256 32m0 128c-13.3 0-24 10.7-24 24v112c0 13.3 10.7 24 24 24s24-10.7 24-24V184c0-13.3-10.7-24-24-24m32 224a32 32 0 1 0-64 0 32 32 0 1 0 64 0"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.1 52.4 442.6 6.5c-1.9-3.9-6.1-6.5-10.5-6.5s-8.5 2.6-10.4 6.5l-16.5 45.9-46 16.8c-4.3 1.6-7.3 5.9-7.2 10.4 0 4.5 3 8.7 7.2 10.2l45.7 16.8 16.8 45.8c1.5 4.4 5.8 7.5 10.4 7.5s8.9-3.1 10.4-7.5l16.5-45.8 45.7-16.8c4.2-1.5 7.2-5.7 7.2-10.2 0-4.6-3-8.9-7.2-10.4zm-132.4 53c-12.5-12.5-32.8-12.5-45.3 0l-2.9 2.9c-22-8-45.8-12.3-70.5-12.3C93.1 96 0 189.1 0 304s93.1 208 208 208 208-93.1 208-208c0-24.7-4.3-48.5-12.2-70.5l2.9-2.9c12.5-12.5 12.5-32.8 0-45.3l-80-80zM200 192c-57.4 0-104 46.6-104 104v8c0 8.8-7.2 16-16 16s-16-7.2-16-16v-8c0-75.1 60.9-136 136-136h8c8.8 0 16 7.2 16 16s-7.2 16-16 16z"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 398.9c58.5-41.1 96-104.1 96-174.9C512 100.3 397.4 0 256 0S0 100.3 0 224c0 70.7 37.5 133.8 96 174.9V464c0 26.5 21.5 48 48 48h48v-48c0-8.8 7.2-16 16-16s16 7.2 16 16v48h64v-48c0-8.8 7.2-16 16-16s16 7.2 16 16v48h48c26.5 0 48-21.5 48-48v-65.1M96 256a64 64 0 1 1 128 0 64 64 0 1 1-128 0m256-64a64 64 0 1 1 0 128 64 64 0 1 1 0-128"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v132.8c0 11.8-3.3 23.5-9.5 33.5L10.3 406.2C3.6 417.2 0 429.7 0 442.6 0 480.9 31.1 512 69.4 512h309.2c38.3 0 69.4-31.1 69.4-69.4 0-12.8-3.6-25.4-10.3-36.4L329.5 230.4c-6.2-10.1-9.5-21.7-9.5-33.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 196.8V64h64v132.8c0 23.7 6.6 46.9 19 67.1l34.5 56.1h-171l34.5-56.1c12.4-20.2 19-43.4 19-67.1"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>');}</style>


  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 12a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M6 13h8l-3.5 3.5 1.42 1.42L17.84 12l-5.92-5.92L10.5 7.5 14 11H6z"/></svg>');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+SC:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans SC";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#computer-vision" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="数学分享站" class="md-header__button md-logo" aria-label="数学分享站" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            数学分享站
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Computer Vision
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="启动暗影模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="启动暗影模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="开启日光模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="开启日光模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mathcourse-share/mathcourse-share.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    courseshare
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="数学分享站" class="md-nav__button md-logo" aria-label="数学分享站" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    数学分享站
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mathcourse-share/mathcourse-share.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    courseshare
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    course
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            course
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../how-to-learn%26solve-question/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    提问的智慧
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Blogs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Blogs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M192 32c0 17.7 14.3 32 32 32 123.7 0 224 100.3 224 224 0 17.7 14.3 32 32 32s32-14.3 32-32C512 128.9 383.1 0 224 0c-17.7 0-32 14.3-32 32m0 96c0 17.7 14.3 32 32 32 70.7 0 128 57.3 128 128 0 17.7 14.3 32 32 32s32-14.3 32-32c0-106-86-192-192-192-17.7 0-32 14.3-32 32m-96 16c0-26.5-21.5-48-48-48S0 117.5 0 144v224c0 79.5 64.5 144 144 144s144-64.5 144-144-64.5-144-144-144h-16v96h16c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48z"/></svg>
  
  <span class="md-ellipsis">
    index
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/archives/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 3h18v4H3zm1 5h16v13H4zm5.5 3a.5.5 0 0 0-.5.5V13h6v-1.5a.5.5 0 0 0-.5-.5z"/></svg>
  
  <span class="md-ellipsis">
    Archives
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Posts
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Posts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/24-12-29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    工作规律
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/24-12-30/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    信息
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/25-01-20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    近期的一些想法
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/FreeSplatter%20%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FreeSplatter 代码解读
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/Gaussian_Splatting_Code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gaussian_Splatting_Code
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/Gaussian_Splatting_%E5%A4%8D%E7%8E%B0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gaussian Splatting 复现
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/OCRN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Beyond Object Recognition: A New Benchmark towards Object Concept Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/ULIP-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ULIP-2: Towards Scalable Multimodal Pre-training for 3D Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/%E7%94%A8AI%E5%90%8E%E7%9A%84%E9%97%AE%E9%A2%98/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一些 AI 与个人学习的思考
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Blogs/posts/notes_software/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    笔记软件选择
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Summaries
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Summaries
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"/></svg>
  
  <span class="md-ellipsis">
    Summaries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Weekly
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Weekly
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_1" >
        
          
          <label class="md-nav__link" for="__nav_4_2_1" id="__nav_4_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_1">
            <span class="md-nav__icon md-icon"></span>
            2024
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W44-10.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W45-11.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W46-11.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W47-11.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W48-11.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W49-12.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W50-12.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W51-12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024-W51-12
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2024/weekly/2024-W52-12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024-W52-12
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2_2" id="__nav_4_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_2">
            <span class="md-nav__icon md-icon"></span>
            2025
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2025/weekly/2025-W01-12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025-W01-12
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2025/weekly/2025-W02-01/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025-W02-01
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2025/weekly/2025-W03-01/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025-W03-01
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2025/weekly/2025-W04-01/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025-W04-01
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/2025/weekly/2025-W05-01/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025-W05-01
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Semesters
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            Semesters
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/Semesters/202409-10.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/Semesters/2024_1_1.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Summaries/Semesters/2024summer_vacation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024年高三-大一暑假总结
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Computer Basic
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Computer Basic
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg>
  
  <span class="md-ellipsis">
    Computer Science Basic
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/15-213/CSAPP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CSAPP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    C++
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            C++
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/C%2B%2B/Accelerated%20C%2B%2B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerated C++
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/C%2B%2B/C%2B%2B%20Basic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C++
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CS61
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            CS61
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/CS61A/CS61A/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CS61A
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/CS61A/Composing_Programs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    COMPOSING PROGRAMS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/CS61C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E8%AE%BE%E8%AE%A1%E7%A1%AC%E4%BB%B6%E8%BD%AF%E4%BB%B6%E6%8E%A5%E5%8F%A3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机组成与设计硬件软件接口
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Network
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            Network
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CS_Basic/Network/Security/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Security
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    AI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg>
  
  <span class="md-ellipsis">
    Artificial Intelligence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Basic
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            Basic
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Dive_into_Deep_Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dive into Deep Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../SLAM14/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    视觉SLAM十四讲
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    统计学习方法
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" checked>
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CS231n
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            CS231n
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Computer Vision
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Computer Vision
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      1 - Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      2 - Image Classification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 - Image Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbor" class="md-nav__link">
    <span class="md-ellipsis">
      K Nearest Neighbor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Classifier
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-loss-functions-and-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      3 - Loss Functions and Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 - Loss Functions and Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sgd-with-momentum" class="md-nav__link">
    <span class="md-ellipsis">
      SGD with Momentum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adagrad-and-rmsprop" class="md-nav__link">
    <span class="md-ellipsis">
      AdaGrad and RMSProp
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adam" class="md-nav__link">
    <span class="md-ellipsis">
      Adam
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-decay" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate Decay
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#second-order-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Second-Order Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-neural-networks-and-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      4 - Neural Networks and Backpropagation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 - Neural Networks and Backpropagation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-convolutional-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      5 - Convolutional Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5 - Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Convolution Layer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Convolution Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1times1-convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      \(1\times1\) Convolution Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Pooling layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-networks-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks (CNN)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-cnn-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      6 - CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6 - CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    <span class="md-ellipsis">
      AlexNet
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg" class="md-nav__link">
    <span class="md-ellipsis">
      VGG
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#googlenet" class="md-nav__link">
    <span class="md-ellipsis">
      GoogLeNet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GoogLeNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inception-module" class="md-nav__link">
    <span class="md-ellipsis">
      Inception Module
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ResNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#residual-connections" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Connections
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture_1" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#senet" class="md-nav__link">
    <span class="md-ellipsis">
      SENet
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#improvements-of-resnet" class="md-nav__link">
    <span class="md-ellipsis">
      Improvements of ResNet
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-interesting-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Other Interesting Networks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-training-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      7 - Training Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7 - Training Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Data Processing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Initialization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#common-pattern-of-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Common Pattern of Regularization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization-term" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization Term
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization_1" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-methods-and-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Other Methods and Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameter Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hyperparameter Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-procedures" class="md-nav__link">
    <span class="md-ellipsis">
      Common Procedures
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-checks" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Checks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-visualizing-and-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      8 - Visualizing and Understanding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8 - Visualizing and Understanding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feature-visualization-and-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Visualization and Inversion
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Visualization and Inversion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visualizing-what-models-have-learned" class="md-nav__link">
    <span class="md-ellipsis">
      Visualizing what models have learned
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-input-pixels" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding input pixels
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding input pixels">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maximally-activating-patches" class="md-nav__link">
    <span class="md-ellipsis">
      Maximally Activating Patches
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#saliency-via-occlusion" class="md-nav__link">
    <span class="md-ellipsis">
      Saliency via Occlusion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#saliency-via-backprop" class="md-nav__link">
    <span class="md-ellipsis">
      Saliency via Backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intermediate-features-via-guided-backprop" class="md-nav__link">
    <span class="md-ellipsis">
      Intermediate Features via Guided Backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-ascent" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Ascent
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adversarial-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Adversarial Examples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deepdream-and-style-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      DeepDream and Style Transfer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DeepDream and Style Transfer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feature-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Inversion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deepdream-amplify-existing-features" class="md-nav__link">
    <span class="md-ellipsis">
      DeepDream: Amplify Existing Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#texture-synthesis" class="md-nav__link">
    <span class="md-ellipsis">
      Texture Synthesis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Texture Synthesis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nearest-neighbor" class="md-nav__link">
    <span class="md-ellipsis">
      Nearest Neighbor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-texture-synthesis" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Texture Synthesis
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#style-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      Style Transfer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Style Transfer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feature-gram-reconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      Feature + Gram Reconstruction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fast-style-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      Fast Style Transfer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-object-detection-and-image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      9 - Object Detection and Image Segmentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9 - Object Detection and Image Segmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#semantic-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Segmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Object Detection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Object Detection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#single-object" class="md-nav__link">
    <span class="md-ellipsis">
      Single Object
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiple-object" class="md-nav__link">
    <span class="md-ellipsis">
      Multiple Object
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multiple Object">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      R-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fast-r-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Fast R-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#faster-r-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Faster R-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#single-stage-object-detectors-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      Single-Stage Object Detectors: YOLO
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Instance Segmentation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-recurrent-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      10 - Recurrent Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10 - Recurrent Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-network-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Neural Network (RNN)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recurrent Neural Network (RNN)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#motivation-sequence-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation: Sequence Processing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vanilla-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Vanilla RNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vanilla RNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#many-to-one" class="md-nav__link">
    <span class="md-ellipsis">
      Many to One
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#many-to-many-type-2" class="md-nav__link">
    <span class="md-ellipsis">
      Many to Many (type 2)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-with-teacher-forcing" class="md-nav__link">
    <span class="md-ellipsis">
      RNN with Teacher Forcing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-with-output-forwarding" class="md-nav__link">
    <span class="md-ellipsis">
      RNN with "Output Forwarding"
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bidirectional-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Bidirectional RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder-decoder-sequence-to-sequence-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder-Decoder Sequence to Sequence RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-image-captioning" class="md-nav__link">
    <span class="md-ellipsis">
      Example: Image Captioning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_2" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short Term Memory (LSTM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-rnn-variants" class="md-nav__link">
    <span class="md-ellipsis">
      Other RNN Variants
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-attention-and-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      11 - Attention and Transformers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11 - Attention and Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn-with-attention" class="md-nav__link">
    <span class="md-ellipsis">
      RNN with Attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      General Attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Self-attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#positional-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      Positional Encoding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#masked-self-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Masked Self-attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-head-self-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-head Self-attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoder-block" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder Block
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder-block" class="md-nav__link">
    <span class="md-ellipsis">
      Decoder Block
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-on-image-captioning-only-with-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Example on Image Captioning (Only with Transformers)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-rnns-to-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Comparing RNNs to Transformer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-convnets-to-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Comparing ConvNets to Transformer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-video-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      12 - Video Understanding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="12 - Video Understanding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#video-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Video Classification
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plain-cnn-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Plain CNN Structure
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Plain CNN Structure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#single-frame-2d-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Single Frame 2D-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#late-fusion" class="md-nav__link">
    <span class="md-ellipsis">
      Late Fusion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#early-fusion" class="md-nav__link">
    <span class="md-ellipsis">
      Early Fusion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3d-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      3D-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c3d-vgg-of-3d-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      C3D (VGG of 3D-CNNs)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#two-stream-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Two-Stream Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#i3d-inflating-2d-networks-to-3d" class="md-nav__link">
    <span class="md-ellipsis">
      I3D (Inflating 2D Networks to 3D)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modeling-long-term-temporal-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Modeling Long-term Temporal Structure
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Modeling Long-term Temporal Structure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#recurrent-convolutional-network" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Convolutional Network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spatio-temporal-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Spatio-temporal Self-attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vision-transformers-for-video" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Transformers for Video
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualizing-video-models" class="md-nav__link">
    <span class="md-ellipsis">
      Visualizing Video Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multimodal-video-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Video Understanding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multimodal Video Understanding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temporal-action-localization" class="md-nav__link">
    <span class="md-ellipsis">
      Temporal Action Localization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spatio-temporal-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Spatio-Temporal Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visually-guided-audio-source-separation" class="md-nav__link">
    <span class="md-ellipsis">
      Visually-guided Audio Source Separation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-generative-models" class="md-nav__link">
    <span class="md-ellipsis">
      13 - Generative Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13 - Generative Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pixelrnn-and-pixelcnn" class="md-nav__link">
    <span class="md-ellipsis">
      PixelRNN and PixelCNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PixelRNN and PixelCNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fully-visible-belief-network-fvbn" class="md-nav__link">
    <span class="md-ellipsis">
      Fully Visible Belief Network (FVBN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pixelrnn" class="md-nav__link">
    <span class="md-ellipsis">
      PixelRNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pixelcnn" class="md-nav__link">
    <span class="md-ellipsis">
      PixelCNN
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variational Autoencoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Autoencoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-autoencoder_1" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variational Autoencoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#character-description" class="md-nav__link">
    <span class="md-ellipsis">
      Character Description
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder" class="md-nav__link">
    <span class="md-ellipsis">
      Decoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-autoencoder-combination-of-encoder-and-decoder" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder (Combination of Encoder and Decoder)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Generative Adversarial Networks (GANs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#motivation-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation &amp; Modeling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Training Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_3" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      14 - Self-supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="14 - Self-supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pretext-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Pretext Tasks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pretext Tasks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rotation" class="md-nav__link">
    <span class="md-ellipsis">
      Rotation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rearrangement" class="md-nav__link">
    <span class="md-ellipsis">
      Rearrangement
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inpainting" class="md-nav__link">
    <span class="md-ellipsis">
      Inpainting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coloring" class="md-nav__link">
    <span class="md-ellipsis">
      Coloring
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary-for-pretext-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Summary for Pretext Tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problems-of-specific-pretext-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Problems of Specific Pretext Tasks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#contrastive-representation-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Representation Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Contrastive Representation Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instance-contrastive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Instance Contrastive Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Instance Contrastive Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simclr" class="md-nav__link">
    <span class="md-ellipsis">
      SimCLR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#momentum-contrastive-learning-moco" class="md-nav__link">
    <span class="md-ellipsis">
      Momentum Contrastive Learning (MoCo)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-contrastive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Contrastive Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sequence Contrastive Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-predictive-coding-cpc" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Predictive Coding (CPC)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-examples-frontier" class="md-nav__link">
    <span class="md-ellipsis">
      Other Examples (Frontier)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Other Examples (Frontier)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-language-image-pre-training-clip" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Language Image Pre-training (CLIP)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-low-level-vision" class="md-nav__link">
    <span class="md-ellipsis">
      15 - Low-Level Vision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-3d-vision" class="md-nav__link">
    <span class="md-ellipsis">
      16 - 3D Vision
    </span>
  </a>
  
    <nav class="md-nav" aria-label="16 - 3D Vision">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#representation" class="md-nav__link">
    <span class="md-ellipsis">
      Representation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Representation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#explicit-vs-implicit" class="md-nav__link">
    <span class="md-ellipsis">
      Explicit vs Implicit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#point-clouds" class="md-nav__link">
    <span class="md-ellipsis">
      Point Clouds
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#polygonal-meshes" class="md-nav__link">
    <span class="md-ellipsis">
      Polygonal Meshes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splines" class="md-nav__link">
    <span class="md-ellipsis">
      Splines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algebraic-surfaces" class="md-nav__link">
    <span class="md-ellipsis">
      Algebraic Surfaces
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constructive-solid-geometry" class="md-nav__link">
    <span class="md-ellipsis">
      Constructive Solid Geometry
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#level-sets" class="md-nav__link">
    <span class="md-ellipsis">
      Level Sets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#voxels" class="md-nav__link">
    <span class="md-ellipsis">
      Voxels
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ai-3d" class="md-nav__link">
    <span class="md-ellipsis">
      AI + 3D
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Image%20Classification-Data-driven%20Approach%2C%20k-Nearest%20Neighbor%2C%20train_val_test%20splits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Classification-Data-driven Approach, k-Nearest Neighbor, train_val_test splits
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Linear%20classification-Support%20Vector%20Machine%2C%20Softmax/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linear classification-Support Vector Machine, Softmax
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Numpy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Numpy
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_4" >
        
          
          <label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    EECS 498-007
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            EECS 498-007
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../EECS%20498-007/KNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../EECS%20498-007/Pytorch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pytorch 的基本使用
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../EECS%20498-007/linear_classifer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linear classifer
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_5" >
        
          
          <label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    FFB6D
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_5">
            <span class="md-nav__icon md-icon"></span>
            FFB6D
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../FFB6D/FFB6D_Conda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FFB6D环境配置指南：原生系统安装
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../FFB6D/FFB6D_Docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docker从入门到实践：以FFB6D环境配置为例
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Robot
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Robot
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Robot/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg>
  
  <span class="md-ellipsis">
    Robot
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Robot/calibration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Calibration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Robot/kalman/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卡尔曼滤波
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Robot/pnp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pnp
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tools
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16h-2v-1H8v1H6v-1H2v5h20v-5h-4zm2-8h-3V6c0-1.1-.9-2-2-2H9c-1.1 0-2 .9-2 2v2H4c-1.1 0-2 .9-2 2v4h4v-2h2v2h8v-2h2v2h4v-4c0-1.1-.9-2-2-2m-5 0H9V6h6z"/></svg>
  
  <span class="md-ellipsis">
    Toolbox
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2" >
        
          
          <label class="md-nav__link" for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Cheat Sheet
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2">
            <span class="md-nav__icon md-icon"></span>
            Cheat Sheet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2_2" >
        
          
          <label class="md-nav__link" for="__nav_8_2_2" id="__nav_8_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    tools
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_8_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2_2">
            <span class="md-nav__icon md-icon"></span>
            tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/tools/adb%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    adb Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/tools/bash%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bash Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/tools/ffmpeg%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ffmpeg Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/tools/gdb%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gdb Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/tools/git%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    git
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/tools/ip%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ip Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/tools/tmux%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tmux Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2_3" >
        
          
          <label class="md-nav__link" for="__nav_8_2_3" id="__nav_8_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    editors
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_8_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2_3">
            <span class="md-nav__icon md-icon"></span>
            editors
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/editors/emacs%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    emacs Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/editors/nano%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nano Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/editors/org%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    org Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/editors/vim%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vim Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2_4" >
        
          
          <label class="md-nav__link" for="__nav_8_2_4" id="__nav_8_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    languages
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_8_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2_4">
            <span class="md-nav__icon md-icon"></span>
            languages
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/languages/javascript%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    javascript Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/languages/python%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    python Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Cheat%20Sheet/languages/vimscript%20Cheat%20Sheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VimScript Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_3" >
        
          
          <label class="md-nav__link" for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    AI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_3">
            <span class="md-nav__icon md-icon"></span>
            AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/AI/prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    prompt
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/AI/prompt_writing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 使用
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_4" >
        
          
          <label class="md-nav__link" for="__nav_8_4" id="__nav_8_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_4">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Blog/Mkdocs_Material/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mkdocs material 超全配置
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_5" >
        
          
          <label class="md-nav__link" for="__nav_8_5" id="__nav_8_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Environment
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_5">
            <span class="md-nav__icon md-icon"></span>
            Environment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Environment/Ubuntu_setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ubuntu 配置
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Environment/environment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Environment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Environment/obsidian_setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    obsidian 配置
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_6" >
        
          
          <label class="md-nav__link" for="__nav_8_6" id="__nav_8_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Make
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_6">
            <span class="md-nav__icon md-icon"></span>
            Make
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Make/CMake/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CMake 相关
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Make/Makeflie/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Makeflie
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_7" >
        
          
          <label class="md-nav__link" for="__nav_8_7" id="__nav_8_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Others
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_7">
            <span class="md-nav__icon md-icon"></span>
            Others
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Others/Chezmoi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 chezmoi 实现跨设备同步配置
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Others/SSH/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SSH配置指南
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Others/zotero_%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zotero_使用指南
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_8" >
        
          
          <label class="md-nav__link" for="__nav_8_8" id="__nav_8_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Terminal
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_8">
            <span class="md-nav__icon md-icon"></span>
            Terminal
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/Terminal/Tabby_Zsh/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tabby + Zsh 配置指南
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tags
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Tags
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tags/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5.5 7A1.5 1.5 0 0 1 4 5.5 1.5 1.5 0 0 1 5.5 4 1.5 1.5 0 0 1 7 5.5 1.5 1.5 0 0 1 5.5 7m15.91 4.58-9-9C12.05 2.22 11.55 2 11 2H4c-1.11 0-2 .89-2 2v7c0 .55.22 1.05.59 1.41l8.99 9c.37.36.87.59 1.42.59s1.05-.23 1.41-.59l7-7c.37-.36.59-.86.59-1.41 0-.56-.23-1.06-.59-1.42"/></svg>
  
  <span class="md-ellipsis">
    Tags
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      1 - Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      2 - Image Classification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 - Image Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbor" class="md-nav__link">
    <span class="md-ellipsis">
      K Nearest Neighbor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Classifier
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-loss-functions-and-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      3 - Loss Functions and Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 - Loss Functions and Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sgd-with-momentum" class="md-nav__link">
    <span class="md-ellipsis">
      SGD with Momentum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adagrad-and-rmsprop" class="md-nav__link">
    <span class="md-ellipsis">
      AdaGrad and RMSProp
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adam" class="md-nav__link">
    <span class="md-ellipsis">
      Adam
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-decay" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate Decay
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#second-order-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Second-Order Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-neural-networks-and-backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      4 - Neural Networks and Backpropagation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 - Neural Networks and Backpropagation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-convolutional-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      5 - Convolutional Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5 - Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Convolution Layer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Convolution Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1times1-convolution-layer" class="md-nav__link">
    <span class="md-ellipsis">
      \(1\times1\) Convolution Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Pooling layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-networks-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks (CNN)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-cnn-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      6 - CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6 - CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    <span class="md-ellipsis">
      AlexNet
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg" class="md-nav__link">
    <span class="md-ellipsis">
      VGG
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#googlenet" class="md-nav__link">
    <span class="md-ellipsis">
      GoogLeNet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GoogLeNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inception-module" class="md-nav__link">
    <span class="md-ellipsis">
      Inception Module
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ResNet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#residual-connections" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Connections
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture_1" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#senet" class="md-nav__link">
    <span class="md-ellipsis">
      SENet
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#improvements-of-resnet" class="md-nav__link">
    <span class="md-ellipsis">
      Improvements of ResNet
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-interesting-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Other Interesting Networks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-training-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      7 - Training Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7 - Training Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Data Processing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Initialization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#common-pattern-of-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      Common Pattern of Regularization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization-term" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization Term
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization_1" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-methods-and-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Other Methods and Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperparameter-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Hyperparameter Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hyperparameter Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-procedures" class="md-nav__link">
    <span class="md-ellipsis">
      Common Procedures
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-checks" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Checks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-visualizing-and-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      8 - Visualizing and Understanding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8 - Visualizing and Understanding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feature-visualization-and-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Visualization and Inversion
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Feature Visualization and Inversion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visualizing-what-models-have-learned" class="md-nav__link">
    <span class="md-ellipsis">
      Visualizing what models have learned
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-input-pixels" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding input pixels
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding input pixels">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maximally-activating-patches" class="md-nav__link">
    <span class="md-ellipsis">
      Maximally Activating Patches
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#saliency-via-occlusion" class="md-nav__link">
    <span class="md-ellipsis">
      Saliency via Occlusion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#saliency-via-backprop" class="md-nav__link">
    <span class="md-ellipsis">
      Saliency via Backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intermediate-features-via-guided-backprop" class="md-nav__link">
    <span class="md-ellipsis">
      Intermediate Features via Guided Backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-ascent" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Ascent
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adversarial-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Adversarial Examples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deepdream-and-style-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      DeepDream and Style Transfer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DeepDream and Style Transfer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feature-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Feature Inversion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deepdream-amplify-existing-features" class="md-nav__link">
    <span class="md-ellipsis">
      DeepDream: Amplify Existing Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#texture-synthesis" class="md-nav__link">
    <span class="md-ellipsis">
      Texture Synthesis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Texture Synthesis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nearest-neighbor" class="md-nav__link">
    <span class="md-ellipsis">
      Nearest Neighbor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-texture-synthesis" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Texture Synthesis
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#style-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      Style Transfer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Style Transfer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feature-gram-reconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      Feature + Gram Reconstruction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fast-style-transfer" class="md-nav__link">
    <span class="md-ellipsis">
      Fast Style Transfer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-object-detection-and-image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      9 - Object Detection and Image Segmentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9 - Object Detection and Image Segmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#semantic-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Segmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Object Detection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Object Detection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#single-object" class="md-nav__link">
    <span class="md-ellipsis">
      Single Object
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiple-object" class="md-nav__link">
    <span class="md-ellipsis">
      Multiple Object
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multiple Object">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      R-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fast-r-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Fast R-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#faster-r-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Faster R-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#single-stage-object-detectors-yolo" class="md-nav__link">
    <span class="md-ellipsis">
      Single-Stage Object Detectors: YOLO
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Instance Segmentation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-recurrent-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      10 - Recurrent Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10 - Recurrent Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-network-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Neural Network (RNN)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recurrent Neural Network (RNN)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#motivation-sequence-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation: Sequence Processing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vanilla-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Vanilla RNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vanilla RNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#many-to-one" class="md-nav__link">
    <span class="md-ellipsis">
      Many to One
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#many-to-many-type-2" class="md-nav__link">
    <span class="md-ellipsis">
      Many to Many (type 2)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-with-teacher-forcing" class="md-nav__link">
    <span class="md-ellipsis">
      RNN with Teacher Forcing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-with-output-forwarding" class="md-nav__link">
    <span class="md-ellipsis">
      RNN with "Output Forwarding"
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bidirectional-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Bidirectional RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder-decoder-sequence-to-sequence-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder-Decoder Sequence to Sequence RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-image-captioning" class="md-nav__link">
    <span class="md-ellipsis">
      Example: Image Captioning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_2" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short Term Memory (LSTM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-rnn-variants" class="md-nav__link">
    <span class="md-ellipsis">
      Other RNN Variants
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-attention-and-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      11 - Attention and Transformers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11 - Attention and Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn-with-attention" class="md-nav__link">
    <span class="md-ellipsis">
      RNN with Attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      General Attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Self-attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#positional-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      Positional Encoding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#masked-self-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Masked Self-attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-head-self-attention-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-head Self-attention Layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoder-block" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder Block
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder-block" class="md-nav__link">
    <span class="md-ellipsis">
      Decoder Block
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-on-image-captioning-only-with-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Example on Image Captioning (Only with Transformers)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-rnns-to-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Comparing RNNs to Transformer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-convnets-to-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Comparing ConvNets to Transformer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-video-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      12 - Video Understanding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="12 - Video Understanding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#video-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Video Classification
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#plain-cnn-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Plain CNN Structure
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Plain CNN Structure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#single-frame-2d-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      Single Frame 2D-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#late-fusion" class="md-nav__link">
    <span class="md-ellipsis">
      Late Fusion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#early-fusion" class="md-nav__link">
    <span class="md-ellipsis">
      Early Fusion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3d-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      3D-CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c3d-vgg-of-3d-cnns" class="md-nav__link">
    <span class="md-ellipsis">
      C3D (VGG of 3D-CNNs)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#two-stream-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Two-Stream Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#i3d-inflating-2d-networks-to-3d" class="md-nav__link">
    <span class="md-ellipsis">
      I3D (Inflating 2D Networks to 3D)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modeling-long-term-temporal-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Modeling Long-term Temporal Structure
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Modeling Long-term Temporal Structure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#recurrent-convolutional-network" class="md-nav__link">
    <span class="md-ellipsis">
      Recurrent Convolutional Network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spatio-temporal-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Spatio-temporal Self-attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vision-transformers-for-video" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Transformers for Video
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualizing-video-models" class="md-nav__link">
    <span class="md-ellipsis">
      Visualizing Video Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multimodal-video-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Video Understanding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multimodal Video Understanding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temporal-action-localization" class="md-nav__link">
    <span class="md-ellipsis">
      Temporal Action Localization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spatio-temporal-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Spatio-Temporal Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visually-guided-audio-source-separation" class="md-nav__link">
    <span class="md-ellipsis">
      Visually-guided Audio Source Separation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-generative-models" class="md-nav__link">
    <span class="md-ellipsis">
      13 - Generative Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13 - Generative Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pixelrnn-and-pixelcnn" class="md-nav__link">
    <span class="md-ellipsis">
      PixelRNN and PixelCNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PixelRNN and PixelCNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fully-visible-belief-network-fvbn" class="md-nav__link">
    <span class="md-ellipsis">
      Fully Visible Belief Network (FVBN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pixelrnn" class="md-nav__link">
    <span class="md-ellipsis">
      PixelRNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pixelcnn" class="md-nav__link">
    <span class="md-ellipsis">
      PixelCNN
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variational Autoencoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Autoencoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-autoencoder_1" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variational Autoencoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#character-description" class="md-nav__link">
    <span class="md-ellipsis">
      Character Description
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder" class="md-nav__link">
    <span class="md-ellipsis">
      Decoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-autoencoder-combination-of-encoder-and-decoder" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder (Combination of Encoder and Decoder)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gans" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Networks (GANs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Generative Adversarial Networks (GANs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#motivation-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation &amp; Modeling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Training Strategy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_3" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      14 - Self-supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="14 - Self-supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pretext-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Pretext Tasks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pretext Tasks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rotation" class="md-nav__link">
    <span class="md-ellipsis">
      Rotation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rearrangement" class="md-nav__link">
    <span class="md-ellipsis">
      Rearrangement
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inpainting" class="md-nav__link">
    <span class="md-ellipsis">
      Inpainting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coloring" class="md-nav__link">
    <span class="md-ellipsis">
      Coloring
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary-for-pretext-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Summary for Pretext Tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problems-of-specific-pretext-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Problems of Specific Pretext Tasks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#contrastive-representation-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Representation Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Contrastive Representation Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instance-contrastive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Instance Contrastive Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Instance Contrastive Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simclr" class="md-nav__link">
    <span class="md-ellipsis">
      SimCLR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#momentum-contrastive-learning-moco" class="md-nav__link">
    <span class="md-ellipsis">
      Momentum Contrastive Learning (MoCo)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-contrastive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Contrastive Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sequence Contrastive Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-predictive-coding-cpc" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Predictive Coding (CPC)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-examples-frontier" class="md-nav__link">
    <span class="md-ellipsis">
      Other Examples (Frontier)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Other Examples (Frontier)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-language-image-pre-training-clip" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Language Image Pre-training (CLIP)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-low-level-vision" class="md-nav__link">
    <span class="md-ellipsis">
      15 - Low-Level Vision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-3d-vision" class="md-nav__link">
    <span class="md-ellipsis">
      16 - 3D Vision
    </span>
  </a>
  
    <nav class="md-nav" aria-label="16 - 3D Vision">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#representation" class="md-nav__link">
    <span class="md-ellipsis">
      Representation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Representation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#explicit-vs-implicit" class="md-nav__link">
    <span class="md-ellipsis">
      Explicit vs Implicit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#point-clouds" class="md-nav__link">
    <span class="md-ellipsis">
      Point Clouds
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#polygonal-meshes" class="md-nav__link">
    <span class="md-ellipsis">
      Polygonal Meshes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splines" class="md-nav__link">
    <span class="md-ellipsis">
      Splines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algebraic-surfaces" class="md-nav__link">
    <span class="md-ellipsis">
      Algebraic Surfaces
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constructive-solid-geometry" class="md-nav__link">
    <span class="md-ellipsis">
      Constructive Solid Geometry
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#level-sets" class="md-nav__link">
    <span class="md-ellipsis">
      Level Sets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#voxels" class="md-nav__link">
    <span class="md-ellipsis">
      Voxels
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ai-3d" class="md-nav__link">
    <span class="md-ellipsis">
      AI + 3D
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                

                  
<a href="https://github.com/mathcourse-share/mathcourse-share.github.io/edit/master/docs/AI/CS231n/CS231n_notes.md" title="edit.link.title" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg>
</a>


<h1 id="computer-vision">Computer Vision</h1>
<p>This note is based on <a href="https://github.com/DaizeDong/Stanford-CS231n-2021-and-2022/">GitHub - DaizeDong/Stanford-CS231n-2021-and-2022: Notes and slides for Stanford CS231n 2021 &amp; 2022 in English. I merged the contents together to get a better version. Assignments are not included. 斯坦福cs231n的课程笔记(英文版本，不含实验代码)，将2021与2022两年的课程进行了合并，分享以供交流。</a><br />
And I will add some blogs, articles and other understanding.</p>
<table>
<thead>
<tr>
<th>Topic</th>
<th>Chapter</th>
</tr>
</thead>
<tbody>
<tr>
<td>Deep Learning Basics</td>
<td>2 - 4</td>
</tr>
<tr>
<td>Perceiving and Understanding the Visual World</td>
<td>5 - 12</td>
</tr>
<tr>
<td>Reconstructing and Interacting with the Visual World</td>
<td>13 - 16</td>
</tr>
<tr>
<td>Human-Centered Applications and Implications</td>
<td>17 - 18</td>
</tr>
</tbody>
</table>
<h2 id="1-introduction">1 - Introduction</h2>
<p>A brief history of computer vision &amp; deep learning...</p>
<h2 id="2-image-classification">2 - Image Classification</h2>
<p><strong>Image Classification:</strong> A core task in Computer Vision. The main drive to the progress of CV.</p>
<p><strong>Challenges:</strong> Viewpoint variation, background clutter, illumination, occlusion, deformation, intra-class variation...</p>
<h3 id="k-nearest-neighbor">K Nearest Neighbor</h3>
<p><strong>Hyperparameters:</strong> Distance metric (<span class="arithmatex">\(p\)</span> norm), <span class="arithmatex">\(k\)</span> number.</p>
<p>Choose hyperparameters using validation set.</p>
<p>Never use k-Nearest Neighbor with pixel distance.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/2-cross_validation.png" /></p>
<h3 id="linear-classifier">Linear Classifier</h3>
<p>Pass...</p>
<h2 id="3-loss-functions-and-optimization">3 - Loss Functions and Optimization</h2>
<h3 id="loss-functions">Loss Functions</h3>
<table>
<thead>
<tr>
<th>Dataset</th>
<th><span class="arithmatex">\(\big\{(x_i,y_i)\big\}_{i=1}^N\\\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>Loss Function</td>
<td><span class="arithmatex">\(L=\frac{1}{N}\sum_{i=1}^NL_i\big(f(x_i,W),y_i\big)\\\)</span></td>
</tr>
<tr>
<td>Loss Function with Regularization</td>
<td><span class="arithmatex">\(L=\frac{1}{N}\sum_{i=1}^NL_i\big(f(x_i,W),y_i\big)+\lambda R(W)\\\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Motivation:</strong> Want to interpret raw classifier scores as probabilities.</p>
<table>
<thead>
<tr>
<th>Softmax Classifier</th>
<th><span class="arithmatex">\(p_i=Softmax(y_i)=\frac{\exp(y_i)}{\sum_{j=1}^N\exp(y_j)}\\\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>Cross Entropy Loss</td>
<td><span class="arithmatex">\(L_i=-y_i\log p_i\\\)</span></td>
</tr>
<tr>
<td>Cross Entropy Loss with Regularization</td>
<td><span class="arithmatex">\(L=-\frac{1}{N}\sum_{i=1}^Ny_i\log p_i+\lambda R(W)\\\)</span></td>
</tr>
</tbody>
</table>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-loss.png" /></p>
<h3 id="optimization">Optimization</h3>
<h4 id="sgd-with-momentum">SGD with Momentum</h4>
<p><strong>Problems that SGD can't handle:</strong></p>
<ol>
<li>Inequality of gradient in different directions.</li>
<li>Local minima and saddle point (much more common in high dimension).</li>
<li>Noise of gradient from mini-batch.</li>
</ol>
<p><strong>Momentum:</strong> Build up “velocity” <span class="arithmatex">\(v_t\)</span> as a running mean of gradients.</p>
<table>
<thead>
<tr>
<th>SGD</th>
<th>SGD + Momentum</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(x_{t+1}=x_t-\alpha\nabla f(x_t)\)</span></td>
<td><span class="arithmatex">\(\begin{align}&amp;v_{t+1}=\rho v_t+\nabla f(x_t)\\&amp;x_{t+1}=x_t-\alpha v_{t+1}\end{align}\)</span></td>
</tr>
<tr>
<td>Naive gradient descent.</td>
<td><span class="arithmatex">\(\rho\)</span> gives "friction", typically <span class="arithmatex">\(\rho=0.9,0.99,0.999,...\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Nesterov Momentum:</strong> Use the derivative on point <span class="arithmatex">\(x_t+\rho v_t\)</span> as gradient instead point <span class="arithmatex">\(x_t\)</span>.</p>
<table>
<thead>
<tr>
<th>Momentum</th>
<th>Nesterov Momentum</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\begin{align}&amp;v_{t+1}=\rho v_t+\nabla f(x_t)\\&amp;x_{t+1}=x_t-\alpha v_{t+1}\end{align}\)</span></td>
<td><span class="arithmatex">\(\begin{align}&amp;v_{t+1}=\rho v_t+\nabla f(x_t+\rho v_t)\\&amp;x_{t+1}=x_t-\alpha v_{t+1}\end{align}\)</span></td>
</tr>
<tr>
<td>Use gradient at current point.</td>
<td>Look ahead for the gradient in velocity direction.</td>
</tr>
</tbody>
</table>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-momentum.png" /></p>
<h4 id="adagrad-and-rmsprop">AdaGrad and RMSProp</h4>
<p><strong>AdaGrad:</strong> Accumulate squared gradient, and gradually decrease the step size.</p>
<p><strong>RMSProp:</strong> Accumulate squared gradient while decaying former ones, and gradually decrease the step size. ("Leaky AdaGrad")</p>
<table>
<thead>
<tr>
<th>AdaGrad</th>
<th>RMSProp</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\begin{align}\text{Initialize:}&amp;\\&amp;r:=0\\\text{Update:}&amp;\\&amp;r:=r+\Big[\nabla f(x_t)\Big]^2\\&amp;x_{t+1}=x_t-\alpha\frac{\nabla f(x_t)}{\sqrt{r}}\end{align}\)</span></td>
<td><span class="arithmatex">\(\begin{align}\text{Initialize:}&amp;\\&amp;r:=0\\\text{Update:}&amp;\\&amp;r:=\rho r+(1-\rho)\Big[\nabla f(x_t)\Big]^2\\&amp;x_{t+1}=x_t-\alpha\frac{\nabla f(x_t)}{\sqrt{r}}\end{align}\)</span></td>
</tr>
<tr>
<td>Continually accumulate squared gradients.</td>
<td><span class="arithmatex">\(\rho\)</span> gives "decay rate", typically <span class="arithmatex">\(\rho=0.9,0.99,0.999,...\)</span></td>
</tr>
</tbody>
</table>
<h4 id="adam">Adam</h4>
<p>Sort of like "RMSProp + Momentum".</p>
<table>
<thead>
<tr>
<th>Adam (simple version)</th>
<th>Adam (full version)</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\begin{align}\text{Initialize:}&amp;\\&amp;r_1:=0\\&amp;r_2:=0\\\text{Update:}&amp;\\&amp;r_1:=\beta_1r_1+(1-\beta_1)\nabla f(x_t)\\&amp;r_2:=\beta_2r_2+(1-\beta_2)\Big[\nabla f(x_t)\Big]^2\\&amp;x_{t+1}=x_t-\alpha\frac{r_1}{\sqrt{r_2}}\end{align}\)</span></td>
<td><span class="arithmatex">\(\begin{align}\text{Initialize:}\\&amp;r_1:=0\\&amp;r_2:=0\\\text{For }i\text{:}\\&amp;r_1:=\beta_1r_1+(1-\beta_1)\nabla f(x_t)\\&amp;r_2:=\beta_2r_2+(1-\beta_2)\Big[\nabla f(x_t)\Big]^2\\&amp;r_1'=\frac{r_1}{1-\beta_1^i}\\&amp;r_2'=\frac{r_2}{1-\beta_2^i}\\&amp;x_{t+1}=x_t-\alpha\frac{r_1'}{\sqrt{r_2'}}\end{align}\)</span></td>
</tr>
<tr>
<td>Build up “velocity” for both gradient and squared gradient.</td>
<td>Correct the "bias" that <span class="arithmatex">\(r_1=r_2=0\)</span> for the first few iterations.</td>
</tr>
</tbody>
</table>
<h4 id="overview">Overview</h4>
<table>
<thead>
<tr>
<th style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-optimization_overview.gif" /></th>
<th style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-optimization_overview2.gif" /></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="learning-rate-decay">Learning Rate Decay</h4>
<p>Reduce learning rate at a few fixed points to get a better convergence over time.</p>
<p><span class="arithmatex">\(\alpha_0\)</span> : Initial learning rate.</p>
<p><span class="arithmatex">\(\alpha_t\)</span> : Learning rate in epoch <span class="arithmatex">\(t\)</span>.</p>
<p><span class="arithmatex">\(T\)</span> : Total number of epochs.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Equation</th>
<th>Picture</th>
</tr>
</thead>
<tbody>
<tr>
<td>Step</td>
<td>Reduce <span class="arithmatex">\(\alpha_t\)</span> constantly  in a fixed step.</td>
<td><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-learning_rate_step.png" /></td>
</tr>
<tr>
<td>Cosine</td>
<td><span class="arithmatex">\(\begin{align}\alpha_t=\frac{1}{2}\alpha_0\Bigg[1+\cos(\frac{t\pi}{T})\Bigg]\end{align}\)</span></td>
<td><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-learning_rate_cosine.png" /></td>
</tr>
<tr>
<td>Linear</td>
<td><span class="arithmatex">\(\begin{align}\alpha_t=\alpha_0\Big(1-\frac{t}{T}\Big)\end{align}\)</span></td>
<td><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-learning_rate_linear.png" /></td>
</tr>
<tr>
<td>Inverse Sqrt</td>
<td><span class="arithmatex">\(\begin{align}\alpha_t=\frac{\alpha_0}{\sqrt{t}}\end{align}\)</span></td>
<td><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-learning_rate_sqrt.png" /></td>
</tr>
</tbody>
</table>
<p>High initial learning rates can make loss explode, linearly increasing learning rate in the first few iterations can prevent this.</p>
<p><strong>Learning rate warm up:</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-learning_rate_increase.png" /></p>
<p><strong>Empirical rule of thumb:</strong> If you increase the batch size by <span class="arithmatex">\(N\)</span>, also scale the initial learning rate by <span class="arithmatex">\(N\)</span> .</p>
<h4 id="second-order-optimization">Second-Order Optimization</h4>
<table>
<thead>
<tr>
<th></th>
<th>Picture</th>
<th>Time Complexity</th>
<th>Space Complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td>First Order</td>
<td><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-first_order.png" /></td>
<td><span class="arithmatex">\(O(n)\)</span></td>
<td><span class="arithmatex">\(O(n)\)</span></td>
</tr>
<tr>
<td>Second Order</td>
<td><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/3-second_order.png" /></td>
<td><span class="arithmatex">\(O(n^2)\)</span> with <strong>BGFS</strong> optimization</td>
<td><span class="arithmatex">\(O(n)\)</span> with <strong>L-BGFS</strong> optimization</td>
</tr>
</tbody>
</table>
<p><strong>L-BGFS :</strong> Limited memory BGFS.</p>
<ol>
<li>Works very well in full batch, deterministic <span class="arithmatex">\(f(x)\)</span>.</li>
<li>Does not transfer very well to mini-batch setting.</li>
</ol>
<h4 id="summary">Summary</h4>
<table>
<thead>
<tr>
<th>Method</th>
<th>Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td>Adam</td>
<td>Often chosen as default method.<br>Work ok even with constant learning rate.</td>
</tr>
<tr>
<td>SGD + Momentum</td>
<td>Can outperform Adam.<br>Require more tuning of learning rate and schedule.</td>
</tr>
<tr>
<td>L-BGFS</td>
<td>If can afford to do full batch updates then try out.</td>
</tr>
</tbody>
</table>
<ul>
<li>An article about gradient descent: <a href="https://arxiv.org/pdf/1609.04747">Anoverview of gradient descent optimization algorithms</a></li>
<li>A blog: <a href="https://johnchenresearch.github.io/demon/">An updated overview of recent gradient descent algorithms – John Chen – ML at Rice University</a></li>
</ul>
<h2 id="4-neural-networks-and-backpropagation">4 - Neural Networks and Backpropagation</h2>
<h3 id="neural-networks">Neural Networks</h3>
<p><strong>Motivation:</strong> Inducted bias can appear to be high when using human-designed features.</p>
<p><strong>Activation:</strong> Sigmoid, tanh, ReLU, LeakyReLU...</p>
<p><strong>Architecture:</strong> Input layer, hidden layer, output layer.</p>
<p><strong>Do not use the size of a neural network as the regularizer. Use regularization instead!</strong></p>
<p><strong>Gradient Calculation:</strong> Computational Graph + Backpropagation.</p>
<h3 id="backpropagation">Backpropagation</h3>
<p>Using Jacobian matrix to calculate the gradient of each node in a computation graph.</p>
<p>Suppose that we have a computation flow like this:</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/4-graph.png" /></p>
<table>
<thead>
<tr>
<th>Input X</th>
<th>Input W</th>
<th>Output Y</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(X=\begin{bmatrix}x_1\\x_2\\\vdots\\x_n\end{bmatrix}\)</span></td>
<td><span class="arithmatex">\(W=\begin{bmatrix}w_{11}&amp;w_{12}&amp;\cdots&amp;w_{1n}\\w_{21}&amp;w_{22}&amp;\cdots&amp;w_{2n}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\w_{m1}&amp;w_{m2}&amp;\cdots&amp;w_{mn}\end{bmatrix}\)</span></td>
<td><span class="arithmatex">\(Y=\begin{bmatrix}y_1\\y_2\\\vdots\\y_m\end{bmatrix}\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(n\times 1\)</span></td>
<td><span class="arithmatex">\(m\times n\)</span></td>
<td><span class="arithmatex">\(m\times 1\)</span></td>
</tr>
</tbody>
</table>
<p>After applying feed forward, we can calculate gradients like this:</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/4-graph2.png" /></p>
<table>
<thead>
<tr>
<th>Derivative Matrix of X</th>
<th>Jacobian Matrix of X</th>
<th>Derivative Matrix of Y</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(D_X=\begin{bmatrix}\frac{\partial L}{\partial x_1}\\\frac{\partial L}{\partial x_2}\\\vdots\\\frac{\partial L}{\partial x_n}\end{bmatrix}\)</span></td>
<td><span class="arithmatex">\(J_X=\begin{bmatrix}\frac{\partial y_1}{\partial x_1}&amp;\frac{\partial y_1}{\partial x_2}&amp;\cdots&amp;\frac{\partial y_1}{\partial x_n}\\\frac{\partial y_2}{\partial x_1}&amp;\frac{\partial y_2}{\partial x_2}&amp;\cdots&amp;\frac{\partial y_2}{\partial x_n}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\\frac{\partial y_m}{\partial x_1}&amp;\frac{\partial y_m}{\partial x_2}&amp;\cdots&amp;\frac{\partial y_m}{\partial x_n}\end{bmatrix}\)</span></td>
<td><span class="arithmatex">\(D_Y=\begin{bmatrix}\frac{\partial L}{\partial y_1}\\\frac{\partial L}{\partial y_2}\\\vdots\\\frac{\partial L}{\partial y_m}\end{bmatrix}\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(n\times 1\)</span></td>
<td><span class="arithmatex">\(m\times n\)</span></td>
<td><span class="arithmatex">\(m\times 1\)</span></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Derivative Matrix of W</th>
<th>Jacobian Matrix of W</th>
<th>Derivative Matrix of Y</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(W=\begin{bmatrix}\frac{\partial L}{\partial w_{11}}&amp;\frac{\partial L}{\partial w_{12}}&amp;\cdots&amp;\frac{\partial L}{\partial w_{1n}}\\\frac{\partial L}{\partial w_{21}}&amp;\frac{\partial L}{\partial w_{22}}&amp;\cdots&amp;\frac{\partial L}{\partial w_{2n}}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\\frac{\partial L}{\partial w_{m1}}&amp;\frac{\partial L}{\partial w_{m2}}&amp;\cdots&amp;\frac{\partial L}{\partial w_{mn}}\end{bmatrix}\)</span></td>
<td><span class="arithmatex">\(J_W^{(k)}=\begin{bmatrix}\frac{\partial y_k}{\partial w_{11}}&amp;\frac{\partial y_k}{\partial w_{12}}&amp;\cdots&amp;\frac{\partial y_k}{\partial w_{1n}}\\\frac{\partial y_k}{\partial w_{21}}&amp;\frac{\partial y_k}{\partial w_{22}}&amp;\cdots&amp;\frac{\partial y_k}{\partial w_{2n}}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\\frac{\partial y_k}{\partial w_{m1}}&amp;\frac{\partial y_k}{\partial w_{m2}}&amp;\cdots&amp;\frac{\partial y_k}{\partial w_{mn}}\end{bmatrix}\)</span><br><span class="arithmatex">\(J_W=\begin{bmatrix}J_W^{(1)}&amp;J_W^{(2)}&amp;\cdots&amp;J_W^{(m)}\end{bmatrix}\)</span></td>
<td><span class="arithmatex">\(D_Y=\begin{bmatrix}\frac{\partial L}{\partial y_1}\\\frac{\partial L}{\partial y_2}\\\vdots\\\frac{\partial L}{\partial y_m}\end{bmatrix}\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(m\times n\)</span></td>
<td><span class="arithmatex">\(m\times m\times n\)</span></td>
<td>$ m\times 1$</td>
</tr>
</tbody>
</table>
<p>For each element in <span class="arithmatex">\(D_X\)</span> , we have:</p>
<p><span class="arithmatex">\(D_{Xi}=\frac{\partial L}{\partial x_i}=\sum_{j=1}^m\frac{\partial L}{\partial y_j}\frac{\partial y_j}{\partial x_i}\\\)</span></p>
<h2 id="5-convolutional-neural-networks">5 - Convolutional Neural Networks</h2>
<h3 id="convolution-layer">Convolution Layer</h3>
<h4 id="introduction">Introduction</h4>
<p><strong>Convolve a filter with an image:</strong> Slide the filter spatially within the image, computing dot products in each region.</p>
<p>Giving a <span class="arithmatex">\(32\times32\times3\)</span> image and a <span class="arithmatex">\(5\times5\times3\)</span> filter, a convolution looks like:</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/5-convolution.png" /></p>
<p>Convolve six <span class="arithmatex">\(5\times5\times3\)</span> filters to a <span class="arithmatex">\(32\times32\times3\)</span> image with step size <span class="arithmatex">\(1\)</span>, we can get a <span class="arithmatex">\(28\times28\times6\)</span> feature:</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/5-convolution_six_filters.png" /></p>
<p>With an activation function after each convolution layer, we can build the ConvNet with a sequence of convolution layers:</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/5-convolution_net.png" /></p>
<p>By <strong>changing the step size</strong> between each move for filters, or <strong>adding zero-padding</strong> around the image, we can modify the size of the output:</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/5-convolution_padding.png" /></p>
<h4 id="1times1-convolution-layer"><span class="arithmatex">\(1\times1\)</span> Convolution Layer</h4>
<p>This kind of layer makes perfect sense. It is usually used to change the dimension (channel) of features.</p>
<p>A <span class="arithmatex">\(1\times1\)</span> convolution layer can also be treated as a full-connected linear layer.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/5-convolution_1times1.png" /></p>
<h4 id="summary_1">Summary</h4>
<table>
<thead>
<tr>
<th><strong>Input</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>image size</td>
<td><span class="arithmatex">\(W_1\times H_1\times C\)</span></td>
</tr>
<tr>
<td>filter size</td>
<td><span class="arithmatex">\(F\times F\times C\)</span></td>
</tr>
<tr>
<td>filter number</td>
<td><span class="arithmatex">\(K\)</span></td>
</tr>
<tr>
<td>stride</td>
<td><span class="arithmatex">\(S\)</span></td>
</tr>
<tr>
<td>zero padding</td>
<td><span class="arithmatex">\(P\)</span></td>
</tr>
<tr>
<td><strong>Output</strong></td>
<td></td>
</tr>
<tr>
<td>output size</td>
<td><span class="arithmatex">\(W_2\times H_2\times K\)</span></td>
</tr>
<tr>
<td>output width</td>
<td><span class="arithmatex">\(W_2=\frac{W_1-F+2P}{S}+1\\\)</span></td>
</tr>
<tr>
<td>output height</td>
<td><span class="arithmatex">\(H_2=\frac{H_1-F+2P}{S}+1\\\)</span></td>
</tr>
<tr>
<td><strong>Parameters</strong></td>
<td></td>
</tr>
<tr>
<td>parameter number (weight)</td>
<td><span class="arithmatex">\(F^2CK\)</span></td>
</tr>
<tr>
<td>parameter number (bias)</td>
<td><span class="arithmatex">\(K\)</span></td>
</tr>
</tbody>
</table>
<h3 id="pooling-layer">Pooling layer</h3>
<p>Make the representations smaller and more manageable.</p>
<p><strong>An example of max pooling:</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/5-pooling.png" /></p>
<table>
<thead>
<tr>
<th><strong>Input</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>image size</td>
<td><span class="arithmatex">\(W_1\times H_1\times C\)</span></td>
</tr>
<tr>
<td>spatial extent</td>
<td><span class="arithmatex">\(F\times F\)</span></td>
</tr>
<tr>
<td>stride</td>
<td><span class="arithmatex">\(S\)</span></td>
</tr>
<tr>
<td><strong>Output</strong></td>
<td></td>
</tr>
<tr>
<td>output size</td>
<td><span class="arithmatex">\(W_2\times H_2\times C\)</span></td>
</tr>
<tr>
<td>output width</td>
<td><span class="arithmatex">\(W_2=\frac{W_1-F}{S}+1\\\)</span></td>
</tr>
<tr>
<td>output height</td>
<td><span class="arithmatex">\(H_2=\frac{H_1-F}{S}+1\\\)</span></td>
</tr>
</tbody>
</table>
<h3 id="convolutional-neural-networks-cnn">Convolutional Neural Networks (CNN)</h3>
<p>CNN stack CONV, POOL, FC layers.</p>
<p><strong>CNN Trends:</strong></p>
<ol>
<li>Smaller filters and deeper architectures.</li>
<li>Getting rid of POOL/FC layers (just CONV).</li>
</ol>
<p><strong>Historically architectures of CNN looked like:</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/5-model_history.png" /></p>
<p>where usually <span class="arithmatex">\(m\)</span> is large, <span class="arithmatex">\(0\le n\le5\)</span>, <span class="arithmatex">\(0\le k\le2\)</span>.</p>
<p>Recent advances such as <strong>ResNet</strong> / <strong>GoogLeNet</strong> have challenged this paradigm.</p>
<h2 id="6-cnn-architectures">6 - CNN Architectures</h2>
<p>Best model in ImageNet competition:</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-image_net.png" /></p>
<h3 id="alexnet">AlexNet</h3>
<p>8 layers.</p>
<p>First use of ConvNet in image classification problem.</p>
<p>Filter size decreases in deeper layer.</p>
<p>Channel number increases in deeper layer.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-alexnet.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-alexnet_p.png" /></p>
<h3 id="vgg">VGG</h3>
<p>19 layers. (also provide 16 layers edition)</p>
<p>Static filter size (<span class="arithmatex">\(3\times3\)</span>) in all layers:</p>
<ol>
<li>The effective receptive field expands with the layer gets deeper.</li>
<li>Deeper architecture gets more non-linearities and few parameters.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-vgg_field.png" /></p>
<p>Most memory is in early convolution layers.</p>
<p>Most parameter is in late FC layers.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-vgg.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-vgg_p.png" /></p>
<h3 id="googlenet">GoogLeNet</h3>
<p>22 layers.</p>
<p>No FC layers, only 5M parameters. ( <span class="arithmatex">\(8.3\%\)</span> of AlexNet, <span class="arithmatex">\(3.7\%\)</span> of VGG )</p>
<p>Devise efficient "inception module".</p>
<h4 id="inception-module">Inception Module</h4>
<p>Design a good local network topology (network within a network) and then stack these modules on top of each other.</p>
<p><strong>Naive Inception Module:</strong></p>
<ol>
<li>Apply parallel filter operations on the input from previous layer.</li>
<li>Concatenate all filter outputs together channel-wise.</li>
<li><strong>Problem:</strong> The depth (channel number) increases too fast, costing expensive computation.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-googlenet_inception.png" /></p>
<p><strong>Inception Module with Dimension Reduction:</strong></p>
<ol>
<li>Add "bottle neck" layers to reduce the dimension.</li>
<li>Also get fewer computation cost.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-googlenet_inception_revised.png" /></p>
<h4 id="architecture">Architecture</h4>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-googlenet_p.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-googlenet_p2.png" /></p>
<h3 id="resnet">ResNet</h3>
<p>152 layers for ImageNet.</p>
<p>Devise "residual connections".</p>
<p>Use BN in place of dropout.</p>
<h4 id="residual-connections">Residual Connections</h4>
<p><strong>Hypothesis:</strong> Deeper models have more representation power than shallow ones. But they are harder to optimize.</p>
<p><strong>Solution:</strong> Use network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-resnet_residual.png" /></p>
<p>It is necessary to use ReLU as activation function, in order to apply identity mapping when <span class="arithmatex">\(F(x)=0\)</span> .</p>
<h4 id="architecture_1">Architecture</h4>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-resnet_train.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-resnet_p.png" /></p>
<h3 id="senet">SENet</h3>
<p>Using ResNeXt-152 as a base architecture.</p>
<p>Add a “feature recalibration” module. <strong>(adjust weights of each channel)</strong></p>
<p>Using the <strong>global avg-pooling layer</strong> + <strong>FC layers</strong> to determine feature map weights.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-senet_p.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/6-senet_p2.png" /></p>
<h3 id="improvements-of-resnet">Improvements of ResNet</h3>
<p>Wide Residual Networks, ResNeXt, DenseNet, MobileNets...</p>
<h3 id="other-interesting-networks">Other Interesting Networks</h3>
<p><strong>NASNet:</strong> Neural Architecture Search with Reinforcement Learning.</p>
<p><strong>EfficientNet:</strong> Smart Compound Scaling.</p>
<h2 id="7-training-neural-networks">7 - Training Neural Networks</h2>
<h3 id="activation-functions">Activation Functions</h3>
<table>
<thead>
<tr>
<th>Activation</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sigmoid, tanh</td>
<td>Do not use.</td>
</tr>
<tr>
<td>ReLU</td>
<td>Use as default.</td>
</tr>
<tr>
<td>Leaky ReLU, Maxout, ELU, SELU</td>
<td>Replace ReLU to squeeze out some marginal gains.</td>
</tr>
<tr>
<td>Swish</td>
<td>No clear usage.</td>
</tr>
</tbody>
</table>
<h3 id="data-processing">Data Processing</h3>
<p>Apply centralization and normalization before training.</p>
<p>In practice for pictures, usually we apply channel-wise centralization only.</p>
<h3 id="weight-initialization">Weight Initialization</h3>
<p>Assume that we have 6 layers in a network.</p>
<p><span class="arithmatex">\(D_i\)</span> : input size of layer <span class="arithmatex">\(i\)</span></p>
<p><span class="arithmatex">\(W_i\)</span> : weights in layer <span class="arithmatex">\(i\)</span></p>
<p><span class="arithmatex">\(X_i\)</span> : output after activation of layer <span class="arithmatex">\(i\)</span>, we have <span class="arithmatex">\(X_i=g(Z_i)=g(W_iX_{i-1}+B_i)\)</span></p>
<p><strong>We initialize each parameter in <span class="arithmatex">\(W_i\)</span> randomly in <span class="arithmatex">\([-k_i,k_i]\)</span> .</strong></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Tanh Activation</th>
<th style="text-align: center;">Output Distribution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(k_i=0.01\)</span></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-sigmoid_0.01.png" /></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(k_i=0.05\)</span></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-sigmoid_0.05.png" /></td>
</tr>
<tr>
<td style="text-align: center;"><strong>Xavier Initialization</strong> <span class="arithmatex">\(k_i=\frac{1}{\sqrt{D_i}\\}\)</span></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-sigmoid_xavier.png" /></td>
</tr>
</tbody>
</table>
<p>When <span class="arithmatex">\(k_i=0.01\)</span>, the variance keeps decreasing as the layer gets deeper. As a result, the output of each neuron in deep layer will all be 0. The partial derivative <span class="arithmatex">\(\frac{\partial Z_i}{\partial W_i}=X_{i-1}=0\\\)</span>. (no gradient)</p>
<p>When <span class="arithmatex">\(k_i=0.05\)</span>, most neurons is saturated. The partial derivative <span class="arithmatex">\(\frac{\partial X_i}{\partial Z_i}=g'(Z_i)=0\\\)</span>. (no gradient)</p>
<p><strong>To solve this problem, We need to keep the variance same in each layer.</strong></p>
<p>Assuming that <span class="arithmatex">\(Var\big(X_{i-1}^{(1)}\big)=Var\big(X_{i-1}^{(2)}\big)=\dots=Var\big(X_{i-1}^{(D_i)}\big)\)</span></p>
<p>We have <span class="arithmatex">\(Z_i=X_{i-1}^{(1)}W_i^{(:,1)}+X_{i-1}^{(2)}W_i^{(:,2)}+\dots+X_{i-1}^{(D_i)}W_i^{(:,D_i)}=\sum_{n=1}^{D_i}X_{i-1}^{(n)}W_i^{(:,n)}\\\)</span></p>
<p>We want <span class="arithmatex">\(Var\big(Z_i\big)=Var\big(X_{i-1}^{(n)}\big)\)</span></p>
<p><strong>Let's do some conduction:</strong></p>
<p><span class="arithmatex">\(\begin{aligned}Var\big(Z_i\big)&amp;=Var\Bigg(\sum_{n=1}^{D_i}X_{i-1}^{(n)}W_i^{(:,n)}\Bigg)\\&amp;=D_i\ Var\Big(X_{i-1}^{(n)}W_i^{(:,n)}\Big)\\&amp;=D_i\ Var\Big(X_{i-1}^{(n)}\Big)\ Var\Big(W_i^{(:,n)}\Big)\end{aligned}\)</span></p>
<p>So <span class="arithmatex">\(Var\big(Z_i\big)=Var\big(X_{i-1}^{(n)}\big)\)</span> only when <span class="arithmatex">\(Var\Big(W_i^{(:,n)}\Big)=\frac{1}{D_i}\\\)</span>, that is to say <span class="arithmatex">\(k_i=\frac{1}{\sqrt{D_i}}\\\)</span></p>
<table>
<thead>
<tr>
<th style="text-align: center;">ReLU Activation</th>
<th style="text-align: center;">Output Distribution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>Xavier Initialization</strong> <span class="arithmatex">\(k_i=\frac{1}{\sqrt{D_i}\\}\)</span></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-relu_xavier.png" /></td>
</tr>
<tr>
<td style="text-align: center;"><strong>Kaiming Initialization</strong> <span class="arithmatex">\(k_i=\sqrt{2D_i}\)</span></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-relu_kaiming.png" /></td>
</tr>
</tbody>
</table>
<p>For ReLU activation, when using xavier initialization, there still exist "variance decreasing" problem.</p>
<p>We can use kaiming initialization instead to fix this.</p>
<h3 id="batch-normalization">Batch Normalization</h3>
<p>Force the inputs to be "nicely scaled" at each layer.</p>
<p><span class="arithmatex">\(N\)</span> : batch size</p>
<p><span class="arithmatex">\(D\)</span> : feature size</p>
<p><span class="arithmatex">\(x\)</span> : input with shape <span class="arithmatex">\(N\times D\)</span> </p>
<p><span class="arithmatex">\(\gamma\)</span> : learnable scale and shift parameter with shape <span class="arithmatex">\(D\)</span></p>
<p><span class="arithmatex">\(\beta\)</span> : learnable scale and shift parameter with shape <span class="arithmatex">\(D\)</span></p>
<p><strong>The procedure of batch normalization:</strong></p>
<ol>
<li>Calculate channel-wise mean <span class="arithmatex">\(\mu_j=\frac{1}{N}\sum_{i=1}^Nx_{i,j}\\\)</span> . The result <span class="arithmatex">\(\mu\)</span> with shape <span class="arithmatex">\(D\)</span> .</li>
<li>Calculate channel-wise variance <span class="arithmatex">\(\sigma_j^2=\frac{1}{N}\sum_{i=1}^N(x_{i,j}-\mu_j)^2\\\)</span> . The result <span class="arithmatex">\(\sigma^2\)</span> with shape <span class="arithmatex">\(D\)</span> .</li>
<li>Calculate normalized <span class="arithmatex">\(\hat{x}_{i,j}=\frac{x_{i,j}-\mu_j}{\sqrt{\sigma_j^2+\epsilon}}\\\)</span> . The result <span class="arithmatex">\(\hat{x}\)</span> with shape <span class="arithmatex">\(N\times D\)</span> .</li>
<li>Scale normalized input to get output <span class="arithmatex">\(y_{i,j}=\gamma_j\hat{x}_{i,j}+\beta_j\)</span> . The result <span class="arithmatex">\(y\)</span> with shape <span class="arithmatex">\(N\times D\)</span> .</li>
</ol>
<p><strong>Why scale:</strong> The constraint "zero-mean, unit variance" may be too hard.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-batch_norm.png" /></p>
<p><strong>Pros:</strong></p>
<ol>
<li>Makes deep networks much easier to train!</li>
<li>Improves gradient flow.</li>
<li>Allows higher learning rates, faster convergence.</li>
<li>Networks become more robust to initialization.</li>
<li>Acts as regularization during training.</li>
<li>Zero overhead at test-time: can be fused with conv!</li>
</ol>
<p><strong>Cons:</strong></p>
<p>Behaves differently during training and testing: this is a very common source of bugs!</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-all_norm.png" /></p>
<h3 id="transfer-learning">Transfer Learning</h3>
<p>Train on a pre-trained model with other datasets.</p>
<p><strong>An empirical suggestion:</strong></p>
<table>
<thead>
<tr>
<th></th>
<th><strong>very similar  dataset</strong></th>
<th><strong>very different  dataset</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>very little data</strong></td>
<td>Use Linear Classifier on top layer.</td>
<td>You’re in trouble… Try linear classifier from different stages.</td>
</tr>
<tr>
<td><strong>quite a lot of data</strong></td>
<td>Finetune a few layers.</td>
<td>Finetune a larger number of layers.</td>
</tr>
</tbody>
</table>
<h3 id="regularization">Regularization</h3>
<h4 id="common-pattern-of-regularization">Common Pattern of Regularization</h4>
<p>Training: Add some kind of randomness. <span class="arithmatex">\(y=f(x,z)\)</span></p>
<p>Testing: Average out randomness (sometimes approximate). <span class="arithmatex">\(y=f(x)=E_z\big[f(x,z)\big]=\int p(z)f(x,z)dz\\\)</span></p>
<h4 id="regularization-term">Regularization Term</h4>
<p>L2 regularization: <span class="arithmatex">\(R(W)=\sum_k\sum_lW_{k,l}^2\)</span> (weight decay)</p>
<p>L1 regularization: <span class="arithmatex">\(R(W)=\sum_k\sum_l|W_{k,l}|\)</span></p>
<p>Elastic net : <span class="arithmatex">\(R(W)=\sum_k\sum_l\big(\beta W_{k,l}^2+|W_{k,l}|\big)\)</span> (L1+L2)</p>
<h4 id="dropout">Dropout</h4>
<p>Training: Randomly set some neurons to 0 with a probability <span class="arithmatex">\(p\)</span> .</p>
<p>Testing: Each neuron multiplies by dropout probability <span class="arithmatex">\(p\)</span> . (scale the output back)</p>
<p><strong>More common:</strong> Scale the output with <span class="arithmatex">\(\frac{1}{p}\)</span> when training, keep the original output when testing.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-dropout_p.png" /></p>
<p><strong>Why dropout works:</strong></p>
<ol>
<li>Forces the network to have a redundant representation. Prevents co-adaptation of features.</li>
<li><strong>Another interpretation:</strong> Dropout is training a large ensemble of models (that share parameters).</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-dropout.png" /></p>
<h4 id="batch-normalization_1">Batch Normalization</h4>
<p>See above.</p>
<h4 id="data-augmentation">Data Augmentation</h4>
<ol>
<li>Horizontal Flips</li>
<li>Random Crops and Scales</li>
<li>Color Jitter</li>
<li>Rotation</li>
<li>Stretching</li>
<li>Shearing</li>
<li>Lens Distortions</li>
<li>...</li>
</ol>
<p>There also exists automatic data augmentation method using neural networks.</p>
<h4 id="other-methods-and-summary">Other Methods and Summary</h4>
<p><strong>DropConnect</strong>: Drop connections between neurons.</p>
<p><strong>Fractional Max Pooling:</strong> Use randomized pooling regions.</p>
<p><strong>Stochastic Depth</strong>: Skip some layers in the network.</p>
<p><strong>Cutout:</strong> Set random image regions to zero.</p>
<p><strong>Mixup:</strong> Train on random blends of images.</p>
<table>
<thead>
<tr>
<th>Regularization Method</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dropout</td>
<td>For large fully-connected layers.</td>
</tr>
<tr>
<td>Batch Normalization &amp; Data Augmentation</td>
<td>Almost always a good idea.</td>
</tr>
<tr>
<td>Cutout &amp; Mixup</td>
<td>For small classification datasets.</td>
</tr>
</tbody>
</table>
<h3 id="hyperparameter-tuning">Hyperparameter Tuning</h3>
<table>
<thead>
<tr>
<th>Most Common Hyperparameters</th>
<th>Less Sensitive Hyperparameters</th>
</tr>
</thead>
<tbody>
<tr>
<td>learning rate<br>learning rate decay schedule<br>weight decay</td>
<td>setting of momentum<br>...</td>
</tr>
</tbody>
</table>
<p><strong>Tips on hyperparameter tuning:</strong></p>
<ol>
<li>Prefer one validation fold to cross-validation.</li>
<li>Search for hyperparameters on log scale. (e.g. multiply the hyperparameter by a fixed number <span class="arithmatex">\(k\)</span> at each search)</li>
<li>Prefer <strong>random search</strong> to grid search.</li>
<li>Careful with best values on border.</li>
<li>Stage your search from coarse to fine.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/7-random_search.png" /></p>
<h4 id="implementation">Implementation</h4>
<p>Have a <strong>worker</strong> that continuously samples random hyperparameters and performs the optimization. During the training, the worker will keep track of the validation performance after every epoch, and writes a model checkpoint to a file.</p>
<p>Have a <strong>master</strong> that launches or kills workers across a computing cluster, and may additionally inspect the checkpoints written by workers and plot their training statistics.</p>
<h4 id="common-procedures">Common Procedures</h4>
<ol>
<li><strong>Check initial loss.</strong></li>
</ol>
<p>Turn off weight decay, sanity check loss at initialization <span class="arithmatex">\(\log(C)\)</span> for softmax with <span class="arithmatex">\(C\)</span> classes.</p>
<ol>
<li><strong>Overfit a small sample. (important)</strong></li>
</ol>
<p>Try to train to 100% training accuracy on a small sample of training data.</p>
<p>Fiddle with architecture, learning rate, weight initialization.</p>
<ol>
<li><strong>Find learning rate that makes loss go down.</strong></li>
</ol>
<p>Use the architecture from the previous step, use all training data, turn on small weight decay, find a learning rate that makes the loss drop significantly within 100 iterations.</p>
<p>Good learning rates to try: <span class="arithmatex">\(0.1,0.01,0.001,0.0001,\dots\)</span></p>
<ol>
<li><strong>Coarse grid, train for 1-5 epochs.</strong></li>
</ol>
<p>Choose a few values of learning rate and weight decay around what worked from Step 3, train a few models for 1-5 epochs.\</p>
<p>Good weight decay to try: <span class="arithmatex">\(0.0001,0.00001,0\)</span></p>
<ol>
<li><strong>Refine grid, train longer.</strong></li>
</ol>
<p>Pick best models from Step 4, train them for longer (10-20 epochs) without learning rate decay.</p>
<ol>
<li><strong>Look at loss and accuracy curves.</strong></li>
<li><strong>GOTO step 5.</strong></li>
</ol>
<h3 id="gradient-checks">Gradient Checks</h3>
<p><a href="https://cs231n.github.io/neural-networks-3/#gradcheck">CS231n Convolutional Neural Networks for Visual Recognition</a></p>
<p>Compute analytical gradient manually using <span class="arithmatex">\(f_a'=\frac{\partial f(x)}{\partial x}=\frac{f(x-h)-f(x+h)}{2h}\\\)</span></p>
<p>Get relative error between numerical gradient <span class="arithmatex">\(f_n'\)</span> and analytical gradient <span class="arithmatex">\(f_a'\)</span> using <span class="arithmatex">\(E=\frac{|f_n'-f_a'|}{\max{|f_n'|,|f_a'|}}\\\)</span></p>
<table>
<thead>
<tr>
<th>Relative Error</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(E&gt;10^{-2}\)</span></td>
<td>Probably <span class="arithmatex">\(f_n'\)</span> is wrong.</td>
</tr>
<tr>
<td><span class="arithmatex">\(10^{-2}&gt;E&gt;10^{-4}\)</span></td>
<td>Not good, should check the gradient.</td>
</tr>
<tr>
<td><span class="arithmatex">\(10^{-4}&gt;E&gt;10^{-6}\)</span></td>
<td>Okay for objectives with kinks. (e.g. ReLU)<br>Not good for objectives with no kink. (e.g. softmax, tanh)</td>
</tr>
<tr>
<td><span class="arithmatex">\(10^{-7}&gt;E\)</span></td>
<td>Good.</td>
</tr>
</tbody>
</table>
<p><strong>Tips on gradient checks:</strong></p>
<ol>
<li>Use double precision.</li>
<li>Use only few data points.</li>
<li>Careful about kinks in the objective. (e.g. <span class="arithmatex">\(x=0\)</span> for ReLU activation)</li>
<li>Careful with the step size <span class="arithmatex">\(h\)</span>.</li>
<li>Use gradient check after the loss starts to go down.</li>
<li>Remember to turn off anything that may affect the gradient. (e.g. <strong>regularization / dropout / augmentations</strong>)</li>
<li>Check only few dimensions for <strong>every parameter</strong>. (reduce time cost)</li>
</ol>
<h2 id="8-visualizing-and-understanding">8 - Visualizing and Understanding</h2>
<h3 id="feature-visualization-and-inversion">Feature Visualization and Inversion</h3>
<h4 id="visualizing-what-models-have-learned">Visualizing what models have learned</h4>
<table>
<thead>
<tr>
<th>Visualize Areas</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Filters</td>
<td>Visualize the raw weights of each convolution kernel. (better in the first layer)</td>
</tr>
<tr>
<td>Final Layer Features</td>
<td>Run dimensionality reduction for features in the last FC layer. (PCA, t-SNE...)</td>
</tr>
<tr>
<td>Activations</td>
<td>Visualize activated areas. (<a href="https://arxiv.org/abs/1506.06579">Understanding Neural Networks Through Deep Visualization</a>)</td>
</tr>
</tbody>
</table>
<h4 id="understanding-input-pixels">Understanding input pixels</h4>
<h5 id="maximally-activating-patches">Maximally Activating Patches</h5>
<ol>
<li>Pick a layer and a channel.</li>
<li>Run many images through the network, record values of the chosen channel.</li>
<li>Visualize image patches that correspond to maximal activation features.</li>
</ol>
<p>For example, we have a layer with shape <span class="arithmatex">\(128\times13\times13\)</span>. We pick the 17th channel from all 128 channels. Then we run many pictures through the network. During each run we can find a maximal activation feature among all the <span class="arithmatex">\(13\times13\)</span> features in channel 17. We then record the corresponding picture patch for each maximal activation feature. At last, we visualize all picture patches for each feature.</p>
<p>This will help us find the relationship between each maximal activation feature and its corresponding picture patches.</p>
<p>(each row of the following picture represents a feature)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-activating_patches.png" /></p>
<h5 id="saliency-via-occlusion">Saliency via Occlusion</h5>
<p>Mask part of the image before feeding to CNN, check how much predicted probabilities change.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-saliency_via_occlusion.png" /></p>
<h5 id="saliency-via-backprop">Saliency via Backprop</h5>
<ol>
<li>Compute gradient of (unnormalized) class score with respect to image pixels.</li>
<li>Take absolute value and max over RGB channels to get <strong>saliency maps</strong>.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-saliency_via_backprop.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-saliency_via_backprop_p.png" /></p>
<h5 id="intermediate-features-via-guided-backprop">Intermediate Features via Guided Backprop</h5>
<ol>
<li>Pick a single intermediate neuron. (e.g. one feature in a <span class="arithmatex">\(128\times13\times13\)</span> feature map)</li>
<li>Compute gradient of neuron value with respect to image pixels.</li>
</ol>
<p><a href="https://arxiv.org/abs/1412.6806">Striving for Simplicity: The All Convolutional Net</a></p>
<p>Just like "Maximally Activating Patches", this could find the part of an image that a neuron responds to.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-guided_backprop.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-guided_backprop_p.png" /></p>
<h5 id="gradient-ascent">Gradient Ascent</h5>
<p>Generate a synthetic image that maximally activates a neuron.</p>
<ol>
<li>Initialize image <span class="arithmatex">\(I\)</span> to zeros.</li>
<li>Forward image to compute current scores <span class="arithmatex">\(S_c(I)\)</span> (for class <span class="arithmatex">\(c\)</span> before softmax).</li>
<li>Backprop to get gradient of neuron value with respect to image pixels.</li>
<li>Make a small update to the image.</li>
</ol>
<p>Objective: <span class="arithmatex">\(\max S_c(I)-\lambda\lVert I\lVert^2\)</span></p>
<p><a href="https://arxiv.org/abs/1312.6034">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-gradient_ascent.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-gradient_ascent_p.png" /></p>
<h3 id="adversarial-examples">Adversarial Examples</h3>
<p>Find an fooling image that can make the network misclassify correctly-classified images when it is added to the image.</p>
<ol>
<li>Start from an arbitrary image.</li>
<li>Pick an arbitrary class.</li>
<li>Modify the image to maximize the class.</li>
<li>Repeat until network is fooled.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-adversarial_examples.png" /></p>
<h3 id="deepdream-and-style-transfer">DeepDream and Style Transfer</h3>
<h4 id="feature-inversion">Feature Inversion</h4>
<p>Given a CNN feature vector <span class="arithmatex">\(\Phi_0\)</span> for an image, find a new image <span class="arithmatex">\(x\)</span> that:</p>
<ol>
<li>Features of new image <span class="arithmatex">\(\Phi(x)\)</span> matches the given feature vector <span class="arithmatex">\(\Phi_0\)</span>.</li>
<li>"looks natural”. (image prior regularization)</li>
</ol>
<p>Objective: <span class="arithmatex">\(\min \lVert\Phi(x)-\Phi_0\lVert+\lambda R(x)\)</span></p>
<p><a href="https://arxiv.org/abs/1412.0035">Understanding Deep Image Representations by Inverting Them</a></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-feature_inversion.png" /></p>
<h4 id="deepdream-amplify-existing-features">DeepDream: Amplify Existing Features</h4>
<p>Given an image, amplify the neuron activations at a layer to generate a new one.</p>
<ol>
<li>Forward: compute activations at chosen layer.</li>
<li>Set gradient of chosen layer equal to its activation.</li>
<li>Backward: Compute gradient on image.</li>
<li>Update image.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-deepdream.png" /></p>
<h4 id="texture-synthesis">Texture Synthesis</h4>
<h5 id="nearest-neighbor">Nearest Neighbor</h5>
<ol>
<li>Generate pixels one at a time in scanline order</li>
<li>Form neighborhood of already generated pixels, copy the nearest neighbor from input.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-texture_synthesis_nn.png" /></p>
<h5 id="neural-texture-synthesis">Neural Texture Synthesis</h5>
<p>Gram Matrix: <a href="https://zhuanlan.zhihu.com/p/187345192">格拉姆矩阵（Gram matrix）详细解读</a></p>
<ol>
<li>Pretrain a CNN on ImageNet.</li>
<li>Run input texture forward through CNN, record activations on every layer.</li>
</ol>
<p>Layer <span class="arithmatex">\(i\)</span> gives feature map of shape <span class="arithmatex">\(C_i\times H_i\times W_i\)</span>.</p>
<ol>
<li>
<p>At each layer compute the <strong>Gram matrix</strong> <span class="arithmatex">\(G_i\)</span> giving outer product of features.</p>
</li>
<li>
<p>Reshape feature map at layer <span class="arithmatex">\(i\)</span> to <span class="arithmatex">\(C_i\times H_iW_i\)</span>.</p>
</li>
<li>
<p>Compute the <strong>Gram matrix</strong> <span class="arithmatex">\(G_i\)</span> with shape <span class="arithmatex">\(C_i\times C_i\)</span>.</p>
</li>
<li>
<p>Initialize generated image from random noise.</p>
</li>
<li>Pass generated image through CNN, compute <strong>Gram matrix</strong> <span class="arithmatex">\(\hat{G}_l\)</span> on each layer.</li>
<li>
<p>Compute loss: Weighted sum of L2 distance between <strong>Gram matrices</strong>.</p>
</li>
<li>
<p><span class="arithmatex">\(E_l=\frac{1}{aN_l^2M_l^2}\sum_{i,j}\Big(G_i^{(i,j)}-\hat{G}_i^{(i,j)}\Big)^2\\\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(\mathcal{L}(\vec{x},\hat{\vec{x}})=\sum_{l=0}^L\omega_lE_l\\\)</span></p>
</li>
<li>
<p>Backprop to get gradient on image.</p>
</li>
<li>Make gradient step on image.</li>
<li>GOTO 5.</li>
</ol>
<p><a href="https://arxiv.org/abs/1505.07376">Texture Synthesis Using Convolutional Neural Networks</a></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-texture_synthesis_neural.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-texture_synthesis_neural_p.png" /></p>
<h4 id="style-transfer">Style Transfer</h4>
<h5 id="feature-gram-reconstruction">Feature + Gram Reconstruction</h5>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-style_transfer.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-style_transfer_p.png" /></p>
<p><strong>Problem:</strong> Style transfer requires many forward / backward passes. Very slow!</p>
<h5 id="fast-style-transfer">Fast Style Transfer</h5>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-style_transfer_fast.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/8-style_transfer_fast_p.png" /></p>
<h2 id="9-object-detection-and-image-segmentation">9 - Object Detection and Image Segmentation</h2>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-tasks.png" /></p>
<h3 id="semantic-segmentation">Semantic Segmentation</h3>
<p><strong>Paired Training Data:</strong> For each training image, each pixel is labeled with a semantic category.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-sematic_segmetation.png" /></p>
<p><strong>Fully Convolutional Network:</strong> Design a network with only convolutional layers without downsampling operators to make predictions for pixels all at once!</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-sematic_segmetation_full_conv.png" /></p>
<p><strong>Problem:</strong> Convolutions at original image resolution will be very expensive...</p>
<p><strong>Solution:</strong> Design fully convolutional network with <strong>downsampling</strong> and <strong>upsampling</strong> inside it!</p>
<ul>
<li><strong>Downsampling:</strong> Pooling, strided convolution.</li>
<li><strong>Upsampling:</strong> Unpooling, transposed convolution.</li>
</ul>
<p><strong>Unpooling:</strong></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Nearest Neighbor</th>
<th style="text-align: center;">"Bed of Nails"</th>
<th style="text-align: center;">"Position Memory"</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-unpooling_nn.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-unpooling_bed_of_nails.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-unpooling_memory.png" /></td>
</tr>
</tbody>
</table>
<p><strong>Transposed Convolution:</strong> (example size <span class="arithmatex">\(3\times3\)</span>, stride <span class="arithmatex">\(2\)</span>, pad <span class="arithmatex">\(1\)</span>)</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Normal Convolution</th>
<th style="text-align: center;">Transposed Convolution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-transposed_convolution_normal.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-transposed_convolution.png" /></td>
</tr>
<tr>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-transposed_convolution_normal_m.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-transposed_convolution_m.png" /></td>
</tr>
</tbody>
</table>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-sematic_segmetation_full_conv_down.png" /></p>
<h3 id="object-detection">Object Detection</h3>
<h4 id="single-object">Single Object</h4>
<p>Classification + Localization. (classification + regression problem)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-object_detection_single.png" /></p>
<h4 id="multiple-object">Multiple Object</h4>
<h5 id="r-cnn">R-CNN</h5>
<p>Using selective search to find “blobby” image regions that are likely to contain objects.</p>
<ol>
<li>Find regions of interest (RoI) using selective search. (region proposal)</li>
<li>Forward each region through ConvNet.</li>
<li>Classify features with SVMs.</li>
</ol>
<p><strong>Problem:</strong> Very slow. Need to do 2000 independent forward passes for each image!</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-rcnn.png" /></p>
<h5 id="fast-r-cnn">Fast R-CNN</h5>
<p>Pass the image through ConvNet before cropping. Crop the conv feature instead.</p>
<ol>
<li>Run whole image through ConvNet.</li>
<li>Find regions of interest (RoI) from conv features using selective search. (<strong>region proposal</strong>)</li>
<li>Classify RoIs using CNN.</li>
</ol>
<p><strong>Problem:</strong> Runtime is dominated by region proposals. (about <span class="arithmatex">\(90\%\)</span> time cost)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-fast_rcnn.png" /></p>
<h5 id="faster-r-cnn">Faster R-CNN</h5>
<p>Insert Region Proposal Network (<strong>RPN</strong>) to predict proposals from features.</p>
<p>Otherwise same as Fast R-CNN: Crop features for each proposal, classify each one.</p>
<p><strong>Region Proposal Network (RPN) :</strong> Slide many fixed windows over ConvNet features.</p>
<ol>
<li>Treat each point in the feature map as the <strong>anchor</strong>. </li>
</ol>
<p>We have <span class="arithmatex">\(k\)</span> fixed windows (<strong>anchor boxes</strong>) of different size/scale centered with each anchor.</p>
<ol>
<li>For each anchor box, predict whether it contains an object.</li>
</ol>
<p>For positive boxes, also predict a corrections to the ground-truth box.</p>
<ol>
<li>Slide anchor over the feature map, get the <strong>“objectness” score</strong> for each box at each point.</li>
<li>Sort the “objectness” score, take top <span class="arithmatex">\(300\)</span> as the proposals.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-faster_rcnn_rpn.png" /></p>
<p><strong>Faster R-CNN is a Two-stage object detector:</strong></p>
<ol>
<li>First stage: Run once per image</li>
</ol>
<p>Backbone network</p>
<p>Region proposal network</p>
<ol>
<li>Second stage: Run once per region</li>
</ol>
<p>Crop features: RoI pool / align</p>
<p>Predict object class</p>
<p>Prediction bbox offset</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-faster_rcnn.png" /></p>
<h5 id="single-stage-object-detectors-yolo">Single-Stage Object Detectors: YOLO</h5>
<p><a href="https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection</a></p>
<ol>
<li>Divide image into grids. (example image grids shape <span class="arithmatex">\(7\times7\)</span>)</li>
<li>Set anchors in the middle of each grid.</li>
<li>For each grid:</li>
<li>Using <span class="arithmatex">\(B\)</span> anchor boxes to regress <span class="arithmatex">\(5\)</span> numbers: <span class="arithmatex">\(\text{dx, dy, dh, dw, confidence}\)</span>.</li>
<li>Predict scores for each of <span class="arithmatex">\(C\)</span> classes.</li>
<li>Finally the output is <span class="arithmatex">\(7\times7\times(5B+C)\)</span>.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-yolo.png" /></p>
<h3 id="instance-segmentation">Instance Segmentation</h3>
<p><strong>Mask R-CNN:</strong> Add a small mask network that operates on each RoI and predicts a <span class="arithmatex">\(28\times28\)</span> binary mask.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-mask_rcnn.png" /></p>
<p>Mask R-CNN performs very good results!</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/9-mask_rcnn_p.png" /></p>
<h2 id="10-recurrent-neural-networks">10 - Recurrent Neural Networks</h2>
<p>Supplement content added according to <a href="https://www.deeplearningbook.org/contents/rnn.html">Deep Learning Book - RNN</a>.</p>
<h3 id="recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</h3>
<h4 id="motivation-sequence-processing">Motivation: Sequence Processing</h4>
<table>
<thead>
<tr>
<th style="text-align: center;">One to One</th>
<th style="text-align: center;">One to Many</th>
<th style="text-align: center;">Many to One</th>
<th style="text-align: center;">Many to Many</th>
<th style="text-align: center;">Many to Many</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_seqnence_11.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_seqnence_1m.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_seqnence_m1.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_seqnence_mm.png" /></td>
<td style="text-align: center;"><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_seqnence_mm_2.png" /></td>
</tr>
<tr>
<td style="text-align: center;">Vanilla Neural Networks</td>
<td style="text-align: center;">Image Captioning</td>
<td style="text-align: center;">Action Prediction</td>
<td style="text-align: center;">Video Captioning</td>
<td style="text-align: center;">Video Classification on Frame Level</td>
</tr>
</tbody>
</table>
<h4 id="vanilla-rnn">Vanilla RNN</h4>
<p><span class="arithmatex">\(x^{(t)}\)</span> : Input at time <span class="arithmatex">\(t\)</span>.</p>
<p><span class="arithmatex">\(h^{(t)}\)</span> : State at time <span class="arithmatex">\(t\)</span>.</p>
<p><span class="arithmatex">\(o^{(t)}\)</span> : Output at time <span class="arithmatex">\(t\)</span>​​.</p>
<p><span class="arithmatex">\(y^{(t)}\)</span> : Expected output at time <span class="arithmatex">\(t\)</span>.</p>
<h5 id="many-to-one">Many to One</h5>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_structure_vanilla_m1.png" /></p>
<table>
<thead>
<tr>
<th>Calculation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>State Transition</td>
<td><span class="arithmatex">\(h^{(t)}=\tanh(Wh^{(t-1)}+Ux^{(t)}+b)\)</span></td>
</tr>
<tr>
<td>Output Calculation</td>
<td><span class="arithmatex">\(o^{(\tau)}=\text{sigmoid}\ \big(Vh^{(\tau)}+c\big)\)</span></td>
</tr>
</tbody>
</table>
<h5 id="many-to-many-type-2">Many to Many (type 2)</h5>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_structure_vanilla_mm.png" /></p>
<table>
<thead>
<tr>
<th>Calculation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>State Transition</td>
<td><span class="arithmatex">\(h^{(t)}=\tanh(Wh^{(t-1)}+Ux^{(t)}+b)\)</span></td>
</tr>
<tr>
<td>Output Calculation</td>
<td><span class="arithmatex">\(o^{(t)}=\text{sigmoid}\ \big(Vh^{(t)}+c\big)\)</span></td>
</tr>
</tbody>
</table>
<h4 id="rnn-with-teacher-forcing">RNN with Teacher Forcing</h4>
<p>Update current state according to last-time <strong>output</strong> instead of last-time <strong>state</strong>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_structure_tf.png" /></p>
<table>
<thead>
<tr>
<th>Calculation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>State Transition</td>
<td><span class="arithmatex">\(h^{(t)}=\tanh(Wo^{(t-1)}+Ux^{(t)}+b)\)</span></td>
</tr>
<tr>
<td>Output Calculation</td>
<td><span class="arithmatex">\(o^{(t)}=\text{sigmoid}\ \big(Vh^{(t)}+c\big)\)</span></td>
</tr>
</tbody>
</table>
<h4 id="rnn-with-output-forwarding">RNN with "Output Forwarding"</h4>
<p>We can also combine last-state <strong>output</strong> with this-state <strong>input</strong> together.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_structure_output.png" /></p>
<table>
<thead>
<tr>
<th>Calculation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>State Transition (training)</td>
<td><span class="arithmatex">\(h^{(t)}=\tanh(Wh^{(t-1)}+Ux^{(t)}+Ry^{(t-1)}+b)\)</span></td>
</tr>
<tr>
<td>State Transition (testing)</td>
<td><span class="arithmatex">\(h^{(t)}=\tanh(Wh^{(t-1)}+Ux^{(t)}+Ro^{(t-1)}+b)\)</span></td>
</tr>
<tr>
<td>Output Calculation</td>
<td><span class="arithmatex">\(o^{(t)}=\text{sigmoid}\ \big(Vh^{(t)}+c\big)\)</span></td>
</tr>
</tbody>
</table>
<p>Usually we use <span class="arithmatex">\(o^{(t-1)}\)</span> in place of <span class="arithmatex">\(y^{(t-1)}\)</span> at testing time.</p>
<h4 id="bidirectional-rnn">Bidirectional RNN</h4>
<p>When dealing with <strong>a whole input sequence</strong>, we can process features from two directions.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_structure_bidirectional.png" /></p>
<table>
<thead>
<tr>
<th>Calculation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>State Transition (forward)</td>
<td><span class="arithmatex">\(h^{(t)}=\tanh(W_1h^{(t-1)}+U_1x^{(t)}+b_1)\)</span></td>
</tr>
<tr>
<td>State Transition (backward)</td>
<td><span class="arithmatex">\(g^{(t)}=\tanh(W_2g^{(t+1)}+U_2x^{(t)}+b_2)\)</span></td>
</tr>
<tr>
<td>Output Calculation</td>
<td><span class="arithmatex">\(o^{(t)}=\text{sigmoid}\ \big(Vh^{(t)}+Wg^{(t)}+c\big)\)</span></td>
</tr>
</tbody>
</table>
<h4 id="encoder-decoder-sequence-to-sequence-rnn">Encoder-Decoder Sequence to Sequence RNN</h4>
<p>This is a <strong>many-to-many structure (type 1)</strong>.</p>
<p>First we encode information according to <span class="arithmatex">\(x\)</span> with no output.</p>
<p>Later we decode information according to <span class="arithmatex">\(y\)</span> with no input.</p>
<p><span class="arithmatex">\(C\)</span> : Context vector, often <span class="arithmatex">\(C=h^{(T)}\)</span> (last state of encoder).</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_structure_encoder.png" /></p>
<table>
<thead>
<tr>
<th>Calculation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>State Transition (encode)</td>
<td><span class="arithmatex">\(h^{(t)}=\tanh(W_1h^{(t-1)}+U_1x^{(t)}+b_1)\)</span></td>
</tr>
<tr>
<td>State Transition (decode, training)</td>
<td><span class="arithmatex">\(s^{(t)}=\tanh(W_2s^{(t-1)}+U_2y^{(t)}+TC+b_2)\)</span></td>
</tr>
<tr>
<td>State Transition (decode, testing)</td>
<td><span class="arithmatex">\(s^{(t)}=\tanh(W_2s^{(t-1)}+U_2o^{(t)}+TC+b_2)\)</span></td>
</tr>
<tr>
<td>Output Calculation</td>
<td><span class="arithmatex">\(o^{(t)}=\text{sigmoid}\ \big(Vs^{(t)}+c\big)\)</span></td>
</tr>
</tbody>
</table>
<h4 id="example-image-captioning">Example: Image Captioning</h4>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-rnn_example.png" /></p>
<h4 id="summary_2">Summary</h4>
<p><strong>Advantages of RNN:</strong></p>
<ol>
<li>Can process any length input.</li>
<li>Computation for step <span class="arithmatex">\(t\)</span> can (in theory) use information from many steps back.</li>
<li>Model size doesn’t increase for longer input.</li>
<li>Same weights applied on every timestep, so there is symmetry in how inputs are processed.</li>
</ol>
<p><strong>Disadvantages of RNN:</strong></p>
<ol>
<li>Recurrent computation is slow.</li>
<li>In practice, difficult to access information from many steps back.</li>
<li>Problems with gradient exploding and gradient vanishing. <strong>(check <a href="https://www.deeplearningbook.org/contents/rnn.html">Deep Learning Book - RNN</a> Page 396, Chap 10.7)</strong></li>
</ol>
<h3 id="long-short-term-memory-lstm">Long Short Term Memory (LSTM)</h3>
<p>Add a "cell block" to store history weights.</p>
<p><span class="arithmatex">\(c^{(t)}\)</span> : Cell at time <span class="arithmatex">\(t\)</span>.</p>
<p><span class="arithmatex">\(f^{(t)}\)</span> : <strong>Forget gate</strong> at time <span class="arithmatex">\(t\)</span>. Deciding whether to erase the cell.</p>
<p><span class="arithmatex">\(i^{(t)}\)</span> : <strong>Input gate</strong> at time <span class="arithmatex">\(t\)</span>. Deciding whether to write to the cell.</p>
<p><span class="arithmatex">\(g^{(t)}\)</span> : <strong>External input gate</strong> at time <span class="arithmatex">\(t\)</span>. Deciding how much to write to the cell.</p>
<p><span class="arithmatex">\(o^{(t)}\)</span> : <strong>Output gate</strong> at time <span class="arithmatex">\(t\)</span>. Deciding how much to reveal the cell.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-lstm.png" /></p>
<table>
<thead>
<tr>
<th>Calculation (Gate)</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Forget Gate</td>
<td><span class="arithmatex">\(f^{(t)}=\text{sigmoid}\ \big(W_fh^{(t-1)}+U_fx^{(t)}+b_f\big)\)</span></td>
</tr>
<tr>
<td>Input Gate</td>
<td><span class="arithmatex">\(i^{(t)}=\text{sigmoid}\ \big(W_ih^{(t-1)}+U_ix^{(t)}+b_i\big)\)</span></td>
</tr>
<tr>
<td>External Input Gate</td>
<td><span class="arithmatex">\(g^{(t)}=\tanh(W_gh^{(t-1)}+U_gx^{(t)}+b_g)\)</span></td>
</tr>
<tr>
<td>Output Gate</td>
<td><span class="arithmatex">\(o^{(t)}=\text{sigmoid}\ \big(W_oh^{(t-1)}+U_ox^{(t)}+b_o\big)\)</span></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Calculation (Main)</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Cell Transition</td>
<td><span class="arithmatex">\(c^{(t)}=f^{(t)}\odot c^{(t-1)}+i^{(t)}\odot g^{(t)}\)</span></td>
</tr>
<tr>
<td>State Transition</td>
<td><span class="arithmatex">\(h^{(t)}=o^{(t)}\odot\tanh(c^{(t)})\)</span></td>
</tr>
<tr>
<td>Output Calculation</td>
<td><span class="arithmatex">\(O^{(t)}=\text{sigmoid}\ \big(Vh^{(t)}+c\big)\)</span></td>
</tr>
</tbody>
</table>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/10-lstm_gradient.png" /></p>
<h3 id="other-rnn-variants">Other RNN Variants</h3>
<p>GRU...</p>
<h2 id="11-attention-and-transformers">11 - Attention and Transformers</h2>
<h3 id="rnn-with-attention">RNN with Attention</h3>
<p><strong>Encoder-Decoder Sequence to Sequence RNN Problem:</strong></p>
<p>Input sequence bottlenecked through a fixed-sized context vector <span class="arithmatex">\(C\)</span>. (e.g. <span class="arithmatex">\(T=1000\)</span>)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-rnn_sequence.png" /></p>
<p><strong>Intuitive Solution:</strong></p>
<p>Generate new context vector <span class="arithmatex">\(C_t\)</span> at each step <span class="arithmatex">\(t\)</span> !</p>
<p><span class="arithmatex">\(e_{t,i}\)</span> : Alignment score for input <span class="arithmatex">\(i\)</span> at state <span class="arithmatex">\(t\)</span>. <strong>(scalar)</strong></p>
<p><span class="arithmatex">\(a_{t,i}\)</span> : Attention weight for input <span class="arithmatex">\(i\)</span> at state <span class="arithmatex">\(t\)</span>.</p>
<p><span class="arithmatex">\(C_t\)</span> : Context vector at state <span class="arithmatex">\(t\)</span>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-rnn_attention_1.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-rnn_attention_2.png" /></p>
<table>
<thead>
<tr>
<th>Calculation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Alignment Score</td>
<td><span class="arithmatex">\(e_i^{(t)}=f(s^{(t-1)},h^{(i)})\)</span>.<br>Where <span class="arithmatex">\(f\)</span> is an MLP.</td>
</tr>
<tr>
<td>Attention Weight</td>
<td><span class="arithmatex">\(a_i^{(t)}=\text{softmax}\ (e_i^{(t)})\)</span>.<br>Softmax includes all <span class="arithmatex">\(e_i\)</span> at state <span class="arithmatex">\(t\)</span>.</td>
</tr>
<tr>
<td>Context Vector</td>
<td><span class="arithmatex">\(C^{(t)}=\sum_i a_i^{(t)}h^{(i)}\)</span></td>
</tr>
<tr>
<td>Decoder State Transition</td>
<td><span class="arithmatex">\(s^{(t)}=\tanh(Ws^{(t-1)}+Uy^{(t)}+TC^{(t)}+b)\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Example on Image Captioning:</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-rnn_attention_example.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-rnn_attention_example_2.png" /></p>
<h3 id="general-attention-layer">General Attention Layer</h3>
<p>Add linear transformations to the input vector before attention.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-general_attention.png" /></p>
<p><strong>Notice:</strong></p>
<ol>
<li>Number of queries <span class="arithmatex">\(q\)</span> is variant. (can be <strong>different</strong> from the number of keys <span class="arithmatex">\(k\)</span>)</li>
<li>Number of outputs <span class="arithmatex">\(y\)</span> is equal to the number of queries <span class="arithmatex">\(q\)</span>.</li>
</ol>
<p>Each <span class="arithmatex">\(y\)</span> is a linear weighting of values <span class="arithmatex">\(v\)</span>.</p>
<ol>
<li>Alignment <span class="arithmatex">\(e\)</span> is divided by <span class="arithmatex">\(\sqrt{D}\)</span> to avoid "explosion of softmax", where <span class="arithmatex">\(D\)</span> is the dimension of input feature.</li>
</ol>
<h3 id="self-attention-layer">Self-attention Layer</h3>
<p>The query vectors <span class="arithmatex">\(q\)</span> are also generated from the inputs.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-self_attention.png" /></p>
<p>In this way, the shape of <span class="arithmatex">\(y\)</span> is equal to the shape of <span class="arithmatex">\(x\)</span>.</p>
<p><strong>Example with CNN:</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-self_attention_example.png" /></p>
<h3 id="positional-encoding">Positional Encoding</h3>
<p>Self-attention layer doesn’t care about the orders of the inputs!</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-self_attention_problem.png" /></p>
<p>To encode ordered sequences like language or spatially ordered image features, we can add positional encoding to the inputs.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-self_attention_positional_encoding.png" /></p>
<p>We use a function <span class="arithmatex">\(P:R\rightarrow R^d\)</span> to process the <strong>position</strong> <span class="arithmatex">\(i\)</span> into a <strong>d-dimensional vector</strong> <span class="arithmatex">\(p_i=P(i)\)</span>.</p>
<table>
<thead>
<tr>
<th>Constraint Condition of <span class="arithmatex">\(P\)</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Uniqueness</td>
<td><span class="arithmatex">\(P(i)\ne P(j)\)</span></td>
</tr>
<tr>
<td>Equidistance</td>
<td><span class="arithmatex">\(\lVert P(i+k)-P(i)\rVert^2=\lVert P(j+k)-P(j)\rVert^2\)</span></td>
</tr>
<tr>
<td>Boundness</td>
<td><span class="arithmatex">\(P(i)\in[a,b]\)</span></td>
</tr>
<tr>
<td>Determinacy</td>
<td><span class="arithmatex">\(P(i)\)</span> is always a static value. (function is not dynamic)</td>
</tr>
</tbody>
</table>
<p>We can either train a encoder model, or design a fixed function.</p>
<p><strong>A Practical Positional Encoding Method:</strong> Using <span class="arithmatex">\(\sin\)</span> and <span class="arithmatex">\(\cos\)</span> with different frequency <span class="arithmatex">\(\omega\)</span> at different dimension.</p>
<p><span class="arithmatex">\(P(t)=\begin{bmatrix}\sin(\omega_1,t)\\\cos(\omega_1,t)\\\\\sin(\omega_2,t)\\\cos(\omega_2,t)\\\vdots\\\sin(\omega_{\frac{d}{2}},t)\\\cos(\omega_{\frac{d}{2}},t)\end{bmatrix}\)</span>, where frequency <span class="arithmatex">\(\omega_k=\frac{1}{10000^{\frac{2k}{d}}}\\\)</span>. (wave length <span class="arithmatex">\(\lambda=\frac{1}{\omega}=10000^{\frac{2k}{d}}\\\)</span>)</p>
<p><span class="arithmatex">\(P(t)=\begin{bmatrix}\sin(1/10000^{\frac{2}{d}},t)\\\cos(1/10000^{\frac{2}{d}},t)\\\\\sin(1/10000^{\frac{4}{d}},t)\\\cos(1/10000^{\frac{4}{d}},t)\\\vdots\\\sin(1/10000^1,t)\\\cos(1/10000^1,t)\end{bmatrix}\)</span>, after we substitute <span class="arithmatex">\(\omega_k\)</span> into the equation.</p>
<p><span class="arithmatex">\(P(t)\)</span> is a vector with size <span class="arithmatex">\(d\)</span>, where <span class="arithmatex">\(d\)</span> is a hyperparameter to choose according to the length of input sequence.</p>
<p>An intuition of this method is the binary encoding of numbers.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-self_attention_positional_encoding_intuition.png" /></p>
<p><a href="https://www.bilibili.com/video/BV1E3411B7Bz">[lecture 11d] 注意力和transformer (positional encoding 补充，代码实现，距离计算)</a></p>
<p><strong>It is easy to prove that <span class="arithmatex">\(P(t)\)</span> satisfies "Equidistance":</strong> (set <span class="arithmatex">\(d=2\)</span> for example)</p>
<p><span class="arithmatex">\(\begin{aligned}\lVert P(i+k)-P(i)\rVert^2&amp;=\big[\sin(\omega_1,i+k)-\sin(\omega_1,i)\big]^2+\big[\cos(\omega_1,i+k)-\cos(\omega_1,i)\big]^2\\&amp;=2-2\sin(\omega_1,i+k)\sin(\omega_1,i)-2\cos(\omega_1,i+k)\cos(\omega_1,i)\\&amp;=2-2\cos(\omega_1,k)\end{aligned}\)</span></p>
<p>So the distance is not associated with <span class="arithmatex">\(i\)</span>, we have <span class="arithmatex">\(\lVert P(i+k)-P(i)\rVert^2=\lVert P(j+k)-P(j)\rVert^2\)</span>.</p>
<p><strong>Visualization of <span class="arithmatex">\(P(t)\)</span> features:</strong> (set <span class="arithmatex">\(d=32\)</span>, <span class="arithmatex">\(x\)</span> axis represents the position of sequence)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-self_attention_positional_encoding_p.png" /></p>
<h3 id="masked-self-attention-layer">Masked Self-attention Layer</h3>
<p>To prevent vectors from looking at future vectors, we manually set alignment scores to <span class="arithmatex">\(-\infty\)</span>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-masked_self_attention.png" /></p>
<h3 id="multi-head-self-attention-layer">Multi-head Self-attention Layer</h3>
<p>Multiple self-attention heads in parallel.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-multihead_self_attention.png" /></p>
<h3 id="transformer">Transformer</h3>
<p><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></p>
<h4 id="encoder-block">Encoder Block</h4>
<p><strong>Inputs:</strong> Set of vectors <span class="arithmatex">\(z\)</span>. (in which <span class="arithmatex">\(z_i\)</span> can be a <strong>word</strong> in a sentence, or a <strong>pixel</strong> in a picture...)</p>
<p><strong>Output:</strong> Set of context vectors <span class="arithmatex">\(c\)</span>. (encoded <strong>features</strong> of <span class="arithmatex">\(z\)</span>)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-transformer_encoder.png" /></p>
<p>The number of blocks <span class="arithmatex">\(N=6\)</span> in original paper.</p>
<p><strong>Notice:</strong></p>
<ol>
<li>Self-attention is the only interaction <strong>between vectors</strong> <span class="arithmatex">\(x_0,x_1,\dots,x_n\)</span>.</li>
<li>Layer norm and MLP operate independently <strong>per vector</strong>.</li>
<li>Highly scalable, highly parallelizable, but high memory usage.</li>
</ol>
<h4 id="decoder-block">Decoder Block</h4>
<p><strong>Inputs:</strong> Set of vectors <span class="arithmatex">\(y\)</span>. (<span class="arithmatex">\(y_i\)</span> can be a <strong>word</strong> in a sentence, or a <strong>pixel</strong> in a picture...)</p>
<p><strong>Inputs:</strong> Set of context vectors <span class="arithmatex">\(c\)</span>.</p>
<p><strong>Output:</strong> Set of vectors <span class="arithmatex">\(y'\)</span>. (decoded result, <span class="arithmatex">\(y'_i=y_{i+1}\)</span> for the first <span class="arithmatex">\(n-1\)</span> number of <span class="arithmatex">\(y'\)</span>)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-transformer_decoder.png" /></p>
<p>The number of blocks <span class="arithmatex">\(N=6\)</span> in original paper.</p>
<p><strong>Notice:</strong></p>
<ol>
<li>Masked self-attention only interacts with <strong>past inputs</strong>.</li>
<li>Multi-head attention block is <strong>NOT</strong> self-attention. It attends over encoder outputs.</li>
<li>Highly scalable, highly parallelizable, but high memory usage. (same as encoder)</li>
</ol>
<p><strong>Why we need mask in decoder:</strong></p>
<ol>
<li>Needs for the special formation of output <span class="arithmatex">\(y'_i=y_{i+1}\)</span>.</li>
<li>Needs for parallel computation.</li>
</ol>
<p><a href="https://zhuanlan.zhihu.com/p/166608727">举个例子讲下transformer的输入输出细节及其他</a></p>
<p><a href="https://blog.csdn.net/season77us/article/details/104144613">在测试或者预测时，Transformer里decoder为什么还需要seq mask？</a></p>
<h4 id="example-on-image-captioning-only-with-transformers">Example on Image Captioning (Only with Transformers)</h4>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-transformer_example.png" /></p>
<h3 id="comparing-rnns-to-transformer">Comparing RNNs to Transformer</h3>
<table>
<thead>
<tr>
<th></th>
<th>RNNs</th>
<th>Transformer</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Pros</strong></td>
<td>LSTMs work reasonably well for <strong>long sequences</strong>.</td>
<td>1. Good at <strong>long sequences</strong>. Each attention calculation looks at all inputs.<br>2. Can operate over unordered sets or <strong>ordered sequences</strong> with positional encodings.<br>3. <strong>Parallel computation:</strong> All alignment and attention scores for all inputs can be done in parallel.</td>
</tr>
<tr>
<td><strong>Cons</strong></td>
<td>1. Expects an <strong>ordered sequences</strong> of inputs.<br>2. <strong>Sequential computation:</strong> Subsequent hidden states can only be computed after the previous ones are done.</td>
<td><strong>Requires a lot of memory:</strong> <span class="arithmatex">\(N\times M\)</span> alignment and attention scalers need to be calculated and stored for a single self-attention head.</td>
</tr>
</tbody>
</table>
<h3 id="comparing-convnets-to-transformer">Comparing ConvNets to Transformer</h3>
<p>ConvNets strike back!</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/11-transformer_compare.png" /></p>
<h2 id="12-video-understanding">12 - Video Understanding</h2>
<h3 id="video-classification">Video Classification</h3>
<p>Take video classification task for example.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-video_classification.png" /></p>
<p>Input size: <span class="arithmatex">\(C\times T\times H\times W\)</span>.</p>
<p>The problem is, videos are quite big. We can't afford to train on raw videos, instead we train on video clips.</p>
<table>
<thead>
<tr>
<th>Raw Videos</th>
<th>Video Clips</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(1920\times1080,\ 30\text{fps}\)</span></td>
<td><span class="arithmatex">\(112\times112,\ 5\text{f}/3.2\text{s}\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(10\text{GB}/\text{min}\)</span></td>
<td><span class="arithmatex">\(588\text{KB}/\text{min}\)</span></td>
</tr>
</tbody>
</table>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-video_classification_clips.png" /></p>
<h3 id="plain-cnn-structure">Plain CNN Structure</h3>
<h4 id="single-frame-2d-cnn">Single Frame 2D-CNN</h4>
<p>Train a normal 2D-CNN model.</p>
<p>Classify each frame independently.</p>
<p>Average the result of each frame as the final result.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-single_frame_cnn.png" /></p>
<h4 id="late-fusion">Late Fusion</h4>
<p>Get high-level appearance of each frame, and combine them.</p>
<p>Run 2D-CNN on each frame, pool features and feed to Linear Layers.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-late_fusion.png" /></p>
<p><strong>Problem:</strong> Hard to compare low-level motion between frames.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-late_fusion_problem.png" /></p>
<h4 id="early-fusion">Early Fusion</h4>
<p>Compare frames with very first Conv Layer, after that normal 2D-CNN.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-early_fusion.png" /></p>
<p><strong>Problem:</strong> One layer of temporal processing may not be enough!</p>
<h4 id="3d-cnn">3D-CNN</h4>
<p><strong>Convolve on 3 dimensions:</strong> Height, Width, Time.</p>
<p><strong>Input size:</strong> <span class="arithmatex">\(C_{in}\times T\times H\times W\)</span>.</p>
<p><strong>Kernel size:</strong> <span class="arithmatex">\(C_{in}\times C_{out}\times 3\times 3\times 3\)</span>.</p>
<p><strong>Output size:</strong> <span class="arithmatex">\(C_{out}\times T\times H\times W\)</span>. (with zero paddling)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-3d_cnn.png" /></p>
<h4 id="c3d-vgg-of-3d-cnns">C3D (VGG of 3D-CNNs)</h4>
<p>The cost is quite expensive...</p>
<table>
<thead>
<tr>
<th>Network</th>
<th>Calculation</th>
</tr>
</thead>
<tbody>
<tr>
<td>AlexNet</td>
<td>0.7 GFLOP</td>
</tr>
<tr>
<td>VGG-16</td>
<td>13.6 GFLOP</td>
</tr>
<tr>
<td>C3D</td>
<td><strong>39.5</strong> GFLOP</td>
</tr>
</tbody>
</table>
<h4 id="two-stream-networks">Two-Stream Networks</h4>
<p>Separate motion and appearance.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-two_stream_flow.png" /></p>
<h4 id="i3d-inflating-2d-networks-to-3d">I3D (Inflating 2D Networks to 3D)</h4>
<p>Take a 2D-CNN architecture.</p>
<p>Replace each 2D conv/pool layer with a 3D version.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-i3d.png" /></p>
<h3 id="modeling-long-term-temporal-structure">Modeling Long-term Temporal Structure</h3>
<h4 id="recurrent-convolutional-network">Recurrent Convolutional Network</h4>
<p>Similar to multi-layer RNN, we replace the <strong>dot-product</strong> operation with <strong>convolution</strong>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-rcn.png" /></p>
<p>Feature size in layer <span class="arithmatex">\(L\)</span>, time <span class="arithmatex">\(t-1\)</span>: <span class="arithmatex">\(W_h\times H\times W\)</span>.</p>
<p>Feature size in layer <span class="arithmatex">\(L-1\)</span>, time <span class="arithmatex">\(t\)</span>: <span class="arithmatex">\(W_x\times H\times W\)</span>.</p>
<p>Feature size in layer <span class="arithmatex">\(L\)</span>, time <span class="arithmatex">\(t\)</span>: <span class="arithmatex">\((W_h+W_x)\times H\times W\)</span>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-rcn_inside.png" /></p>
<p><strong>Problem:</strong> RNNs are slow for long sequences. (can’t be parallelized)</p>
<h4 id="spatio-temporal-self-attention">Spatio-temporal Self-attention</h4>
<p>Introduce self-attention into video classification problems.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-self_attention.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-self_attention_net.png" /></p>
<h4 id="vision-transformers-for-video">Vision Transformers for Video</h4>
<p>Factorized attention: Attend over space / time.</p>
<p>So many papers...</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-vision_transformer.png" /></p>
<h3 id="visualizing-video-models">Visualizing Video Models</h3>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-video_visualizing.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-video_visualizing_2.png" /></p>
<h3 id="multimodal-video-understanding">Multimodal Video Understanding</h3>
<h4 id="temporal-action-localization">Temporal Action Localization</h4>
<p>Given a long untrimmed video sequence, identify frames corresponding to different actions.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-multimodal_temporal_localization.png" /></p>
<h4 id="spatio-temporal-detection">Spatio-Temporal Detection</h4>
<p>Given a long untrimmed video, detect all the people in both space and time and classify the activities they are performing.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-multimodal_s_t_detection.png" /></p>
<h4 id="visually-guided-audio-source-separation">Visually-guided Audio Source Separation</h4>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/12-multimodal_voice_separation.png" /></p>
<p>And So on...</p>
<h2 id="13-generative-models">13 - Generative Models</h2>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-generative_model.png" /></p>
<h3 id="pixelrnn-and-pixelcnn">PixelRNN and PixelCNN</h3>
<h4 id="fully-visible-belief-network-fvbn">Fully Visible Belief Network (FVBN)</h4>
<p><span class="arithmatex">\(p(x)\)</span> : Likelihood of image <span class="arithmatex">\(x\)</span>.</p>
<p><span class="arithmatex">\(p(x_1,x_2,\dots,x_n)\)</span> : Joint likelihood of all <span class="arithmatex">\(n\)</span> pixels in image <span class="arithmatex">\(x\)</span>.</p>
<p><span class="arithmatex">\(p(x_i|x_1,x_2,\dots,x_{i-1})\)</span> : Probability of pixel <span class="arithmatex">\(i\)</span> value given all previous pixels.</p>
<p>For explicit density models, we have <span class="arithmatex">\(p(x)=p(x_1,x_2,\dots,x_n)=\prod_{i=1}^np(x_i|x_1,x_2,\dots,x_{i-1})\\\)</span>.</p>
<p><strong>Objective:</strong> Maximize the likelihood of training data.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-likelihood.png" /></p>
<h4 id="pixelrnn">PixelRNN</h4>
<p>Generate image pixels starting from corner.</p>
<p>Dependency on previous pixels modeled using an RNN (LSTM).</p>
<p><strong>Drawback:</strong> Sequential generation is slow in both training and inference!</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-pixel_rnn.png" /></p>
<h4 id="pixelcnn">PixelCNN</h4>
<p>Still generate image pixels starting from corner.</p>
<p>Dependency on previous pixels modeled using a CNN over context region (masked convolution).</p>
<p><strong>Drawback:</strong> Though its training is faster, its generation is still slow. <strong>(pixel by pixel)</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-pixel_cnn.png" /></p>
<h3 id="variational-autoencoder">Variational Autoencoder</h3>
<p>Supplement content added according to <a href="https://arxiv.org/abs/1606.05908">Tutorial on Variational Autoencoders</a>. (<strong>paper with notes:</strong> <a href="..\Variational Autoencoder\papes\VAE Tutorial.pdf">VAE Tutorial.pdf</a>)</p>
<p><a href="https://zhuanlan.zhihu.com/p/34998569">变分自编码器VAE：原来是这么一回事 | 附开源代码</a></p>
<h4 id="autoencoder">Autoencoder</h4>
<p>Learn a lower-dimensional feature representation with unsupervised approaches.</p>
<p><span class="arithmatex">\(x\rightarrow z\)</span> : Dimension reduction for input features.</p>
<p><span class="arithmatex">\(z\rightarrow \hat{x}\)</span> : Reconstruct input features.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-autoencoder.png" /></p>
<p>After training, we throw the decoder away and use the encoder for transferring.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-autoencoder_transfer.png" /></p>
<p><strong>For generative models, there is a problem:</strong></p>
<p>We can’t generate new images from an autoencoder because we don’t know the space of <span class="arithmatex">\(z\)</span>.</p>
<h4 id="variational-autoencoder_1">Variational Autoencoder</h4>
<h5 id="character-description">Character Description</h5>
<p><span class="arithmatex">\(X\)</span> : Images. <strong>(random variable)</strong></p>
<p><span class="arithmatex">\(Z\)</span> : Latent representations. <strong>(random variable)</strong></p>
<p><span class="arithmatex">\(P(X)\)</span> : True distribution of all training images <span class="arithmatex">\(X\)</span>.</p>
<p><span class="arithmatex">\(P(Z)\)</span> : True distribution of all latent representations <span class="arithmatex">\(Z\)</span>.</p>
<p><span class="arithmatex">\(P(X|Z)\)</span> : True <strong>posterior</strong> distribution of all images <span class="arithmatex">\(X\)</span> with condition <span class="arithmatex">\(Z\)</span>.</p>
<p><span class="arithmatex">\(P(Z|X)\)</span> : True <strong>prior</strong> distribution of all latent representations <span class="arithmatex">\(Z\)</span> with condition <span class="arithmatex">\(X\)</span>.</p>
<p><span class="arithmatex">\(Q(Z|X)\)</span> : Approximated <strong>prior</strong> distribution of all latent representations <span class="arithmatex">\(Z\)</span> with condition <span class="arithmatex">\(X\)</span>.</p>
<p><span class="arithmatex">\(x\)</span> : A specific image.</p>
<p><span class="arithmatex">\(z\)</span> : A specific latent representation.</p>
<p><span class="arithmatex">\(\theta\)</span>: Learned parameters in decoder network.</p>
<p><span class="arithmatex">\(\phi\)</span>: Learned parameters in encoder network.</p>
<p><span class="arithmatex">\(p_\theta(x)\)</span> : Probability that <span class="arithmatex">\(x\sim P(X)\)</span>.</p>
<p><span class="arithmatex">\(p_\theta(z)\)</span> : Probability that <span class="arithmatex">\(z\sim P(Z)\)</span>.</p>
<p><span class="arithmatex">\(p_\theta(x|z)\)</span> : Probability that <span class="arithmatex">\(x\sim P(X|Z)\)</span>.</p>
<p><span class="arithmatex">\(p_\theta(z|x)\)</span> : Probability that <span class="arithmatex">\(z\sim P(Z|X)\)</span>.</p>
<p><span class="arithmatex">\(q_\phi(z|x)\)</span> : Probability that <span class="arithmatex">\(z\sim Q(Z|X)\)</span>.</p>
<h5 id="decoder">Decoder</h5>
<p><strong>Objective:</strong></p>
<p>Generate new images from <span class="arithmatex">\(\mathscr{z}\)</span>.</p>
<ol>
<li>Generate a value <span class="arithmatex">\(z^{(i)}\)</span> from the prior distribution <span class="arithmatex">\(P(Z)\)</span>.</li>
<li>Generate a value <span class="arithmatex">\(x^{(i)}\)</span> from the conditional distribution <span class="arithmatex">\(P(X|Z)\)</span>.</li>
</ol>
<p><strong>Lemma:</strong></p>
<p>Any distribution in <span class="arithmatex">\(d\)</span> dimensions can be generated by taking a set of <span class="arithmatex">\(d\)</span> variables that are <strong>normally distributed</strong> and mapping them through a sufficiently complicated function. (source: <a href="https://arxiv.org/abs/1606.05908">Tutorial on Variational Autoencoders</a>, Page 6)</p>
<p><strong>Solutions:</strong></p>
<ol>
<li>Choose prior distribution <span class="arithmatex">\(P(Z)\)</span> to be a simple distribution, for example <span class="arithmatex">\(P(Z)\sim N(0,1)\)</span>.</li>
<li>Learn the conditional distribution <span class="arithmatex">\(P(X|Z)\)</span> through a neural network (decoder) with parameter <span class="arithmatex">\(\theta\)</span>. </li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-var_autoencoder_decoder.png" /></p>
<h5 id="encoder">Encoder</h5>
<p><strong>Objective:</strong></p>
<p>Learn <span class="arithmatex">\(\mathscr{z}\)</span> with training images.</p>
<p><strong>Given:</strong> (From the decoder, we can deduce the following probabilities.)</p>
<ol>
<li><em>data likelihood:</em> <span class="arithmatex">\(p_\theta(x)=\int p_\theta(x|z)p_\theta(z)dz\)</span>.</li>
<li><em>posterior density:</em> <span class="arithmatex">\(p_\theta(z|x)=\frac{p_\theta(x|z)p_\theta(z)}{p_\theta(x)}=\frac{p_\theta(x|z)p_\theta(z)}{\int p_\theta(x|z)p_\theta(z)dz}\)</span>.</li>
</ol>
<p><strong>Problem:</strong></p>
<p>Both <span class="arithmatex">\(p_\theta(x)\)</span> and <span class="arithmatex">\(p_\theta(z|x)\)</span> are intractable. (can't be optimized directly as they contain <em>integral operation</em>)</p>
<p><strong>Solution:</strong></p>
<p>Learn <span class="arithmatex">\(Q(Z|X)\)</span> to approximate the true posterior <span class="arithmatex">\(P(Z|X)\)</span>.</p>
<p>Use <span class="arithmatex">\(q_\phi(z|x)\)</span> in place of <span class="arithmatex">\(p_\theta(z|x)\)</span>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-var_autoencoder_encoder.png" /></p>
<h5 id="variational-autoencoder-combination-of-encoder-and-decoder">Variational Autoencoder (Combination of Encoder and Decoder)</h5>
<p><strong>Objective:</strong></p>
<p>Maximize <span class="arithmatex">\(p_\theta(x)\)</span> for all <span class="arithmatex">\(x^{(i)}\)</span> in the training set.</p>
<p>$$
\begin{aligned}
\log p_\theta\big(x^{(i)}\big)&amp;=\mathbb{E}<em>{z\sim q</em>\phi\big(z|x^{(i)}\big)}\Big[\log p_\theta\big(x^{(i)}\big)\Big]\</p>
<p>&amp;=\mathbb{E}<em>z\Bigg[\log\frac{p</em>\theta\big(x<sup _i_="(i)">{(i)}|z\big)p_\theta\big(z\big)}{p_\theta\big(z|x</sup>\}\big)}\Bigg]\quad\text{(Bayes' Rule)</p>
<p>&amp;=\mathbb{E}<em>z\Bigg[\log\frac{p</em>\theta\big(x<sup _i_="(i)">{(i)}|z\big)p_\theta\big(z\big)}{p_\theta\big(z|x</sup>\frac{q_\phi\big(z|x}\big)<sup _i_="(i)">{(i)}\big)}{q_\phi\big(z|x</sup>\}\big)}\Bigg]\quad\text{(Multiply by Constant)</p>
<p>&amp;=\mathbb{E}<em>z\Big[\log p</em>\theta\big(x<sup _i_="(i)">{(i)}|z\big)\Big]-\mathbb{E}<em>z\Bigg[\log\frac{q</em>\phi\big(z|x</sup>}\big)}{p_\theta\big(z\big)}\Bigg]+\mathbb{E<em>z\Bigg[\log\frac{p</em>\theta\big(z|x<sup _i_="(i)">{(i)}\big)}{q_\phi\big(z|x</sup>\}\big)}\Bigg]\quad\text{(Logarithm)</p>
<p>&amp;=\mathbb{E}<em>z\Big[\log p</em>\theta\big(x<sup _i_="(i)">{(i)}|z\big)\Big]-D_{\text{KL}}\Big[q_\phi\big(z|x</sup>\Big[p_\theta\big(z|x}\big)||p_\theta\big(z\big)\Big]+D_{\text{KL}<sup _i_="(i)">{(i)}\big)||q_\phi\big(z|x</sup>
\end{aligned}
$$}\big)\Big]\quad\text{(KL Divergence)</p>
<p><strong>Analyze the Formula by Term:</strong></p>
<p><span class="arithmatex">\(\mathbb{E}_z\Big[\log p_\theta\big(x^{(i)}|z\big)\Big]\)</span>: Decoder network gives <span class="arithmatex">\(p_\theta\big(x^{(i)}|z\big)\)</span>, can compute estimate of this term through sampling.</p>
<p><span class="arithmatex">\(D_{\text{KL}}\Big[q_\phi\big(z|x^{(i)}\big)||p_\theta\big(z\big)\Big]\)</span>: This KL term (between Gaussians for encoder and <span class="arithmatex">\(z\)</span> prior) has nice closed-form solution!</p>
<p><span class="arithmatex">\(D_{\text{KL}}\Big[p_\theta\big(z|x^{(i)}\big)||q_\phi\big(z|x^{(i)}\big)\Big]\)</span>: The part <span class="arithmatex">\(p_\theta\big(z|x^{(i)}\big)\)</span> is intractable. <strong>However, we know KL divergence always <span class="arithmatex">\(\ge0\)</span>.</strong></p>
<p><strong>Tractable Lower Bound:</strong></p>
<p>We can maximize the lower bound of that formula.</p>
<p>As <span class="arithmatex">\(D_{\text{KL}}\Big[p_\theta\big(z|x^{(i)}\big)||q_\phi\big(z|x^{(i)}\big)\Big]\ge0\)</span> , we can deduce that:</p>
<p>$$
\begin{aligned}
\log p_\theta\big(x^{(i)}\big)&amp;=\mathbb{E}<em>z\Big[\log p</em>\theta\big(x<sup _i_="(i)">{(i)}|z\big)\Big]-D_{\text{KL}}\Big[q_\phi\big(z|x</sup>\Big[p_\theta\big(z|x}\big)||p_\theta\big(z\big)\Big]+D_{\text{KL}<sup _i_="(i)">{(i)}\big)||q_\phi\big(z|x</sup>\big)\Big]\</p>
<p>&amp;\ge\mathbb{E}<em>z\Big[\log p</em>\theta\big(x<sup _i_="(i)">{(i)}|z\big)\Big]-D_{\text{KL}}\Big[q_\phi\big(z|x</sup>\big)||p_\theta\big(z\big)\Big]
\end{aligned}
$$</p>
<p>So the loss function <span class="arithmatex">\(\mathcal{L}\big(x^{(i)},\theta,\phi\big)=-\mathbb{E}_z\Big[\log p_\theta\big(x^{(i)}|z\big)\Big]+D_{\text{KL}}\Big[q_\phi\big(z|x^{(i)}\big)||p_\theta\big(z\big)\Big]\)</span>.</p>
<p><span class="arithmatex">\(\mathbb{E}_z\Big[\log p_\theta\big(x^{(i)}|z\big)\Big]\)</span>: <strong><em>Decoder</em></strong>, reconstruct the input data. </p>
<p><span class="arithmatex">\(D_{\text{KL}}\Big[q_\phi\big(z|x^{(i)}\big)||p_\theta\big(z\big)\Big]\)</span>: <strong><em>Encoder</em></strong>, make approximate posterior distribution close to prior.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-var_autoencoder_combination.png" /></p>
<h3 id="generative-adversarial-networks-gans">Generative Adversarial Networks (GANs)</h3>
<h4 id="motivation-modeling">Motivation &amp; Modeling</h4>
<p><strong>Objective:</strong> Not modeling any explicit density function.</p>
<p><strong>Problem:</strong> Want to sample from complex, high-dimensional training distribution. <strong>No direct way to do this!</strong></p>
<p><strong>Solution:</strong> Sample from a simple distribution, e.g. <strong>random noise</strong>. Learn the transformation to training distribution.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-gan_stage1.png" /></p>
<p><strong>Problem:</strong> We can't learn the <strong>mapping relation</strong> between sample <span class="arithmatex">\(z\)</span> and training images.</p>
<p><strong>Solution:</strong> Use a <strong>discriminator network</strong> to tell whether the generate image is within data distribution or not.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-gan_stage2.png" /></p>
<p><strong>Discriminator network:</strong> Try to distinguish between real and fake images.</p>
<p><strong>Generator network:</strong> Try to fool the discriminator by generating real-looking images.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-gan_stage3.png" /></p>
<p><span class="arithmatex">\(x\)</span> : Real data.</p>
<p><span class="arithmatex">\(y\)</span> : Fake data, which is generated by the generator network. <span class="arithmatex">\(y=G_{\theta_g}(z)\)</span>.</p>
<p><span class="arithmatex">\(D_{\theta_d}(x)\)</span> : Discriminator score, which is the likelihood of real image. <span class="arithmatex">\(D_{\theta_d}(x)\in[0,1]\)</span>.</p>
<p><strong>Objective of discriminator network:</strong></p>
<p><span class="arithmatex">\(\max_{\theta_d}\bigg[\mathbb{E}_x\Big(\log D_{\theta_d}(x)\Big)+\mathbb{E}_{z\sim p(z)}\Big(\log\big(1-D_{\theta_d}(y)\big)\Big)\bigg]\)</span></p>
<p><strong>Objective of generator network:</strong></p>
<p><span class="arithmatex">\(\min_{\theta_g}\max_{\theta_d}\bigg[\mathbb{E}_x\Big(\log D_{\theta_d}(x)\Big)+\mathbb{E}_{z\sim p(z)}\Big(\log\big(1-D_{\theta_d}(y)\big)\Big)\bigg]\)</span></p>
<h4 id="training-strategy">Training Strategy</h4>
<p>Two combine this two networks together, we can train them alternately:</p>
<ol>
<li>Gradient <strong>ascent</strong> on discriminator.</li>
</ol>
<p><span class="arithmatex">\(\max_{\theta_d}\bigg[\mathbb{E}_x\Big(\log D_{\theta_d}(x)\Big)+\mathbb{E}_{z\sim p(z)}\Big(\log\big(1-D_{\theta_d}(y)\big)\Big)\bigg]\)</span></p>
<ol>
<li>Gradient <strong>descent</strong> on generator.</li>
</ol>
<p><span class="arithmatex">\(\min_{\theta_g}\bigg[\mathbb{E}_{z\sim p(z)}\Big(\log\big(1-D_{\theta_d}(y)\big)\Big)\bigg]\)</span></p>
<p>However, the gradient of generator decreases with the value itself, making it <strong>hard to optimize</strong>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/13-gan_gradient.png" /></p>
<p>So we replace <span class="arithmatex">\(\log\big(1-D_{\theta_d}(y)\big)\)</span> with <span class="arithmatex">\(-\log D_{\theta_d}(y)\)</span>, and use gradient ascent instead.</p>
<ol>
<li>Gradient <strong>ascent</strong> on discriminator.</li>
</ol>
<p><span class="arithmatex">\(\max_{\theta_d}\bigg[\mathbb{E}_x\Big(\log D_{\theta_d}(x)\Big)+\mathbb{E}_{z\sim p(z)}\Big(\log\big(1-D_{\theta_d}(y)\big)\Big)\bigg]\)</span></p>
<ol>
<li>Gradient <strong>ascent</strong> on generator.</li>
</ol>
<p><span class="arithmatex">\(\max_{\theta_g}\bigg[\mathbb{E}_{z\sim p(z)}\Big(\log D_{\theta_d}(y)\Big)\bigg]\)</span></p>
<h4 id="summary_3">Summary</h4>
<p><strong>Pros:</strong> Beautiful, state-of-the-art samples!</p>
<p><strong>Cons:</strong> </p>
<ol>
<li>Trickier / more unstable to train.</li>
<li>Can’t solve inference queries such as <span class="arithmatex">\(p(x), p(z|x)\)</span>.</li>
</ol>
<h2 id="14-self-supervised-learning">14 - Self-supervised Learning</h2>
<p><strong>Aim:</strong> Solve “pretext” tasks that produce good features for downstream tasks.</p>
<p><strong>Application:</strong></p>
<ol>
<li>Learn a feature extractor from pretext tasks. <strong>(self-supervised)</strong></li>
<li>Attach a shallow network on the feature extractor.</li>
<li>Train the shallow network on target task with small amount of labeled data. <strong>(supervised)</strong></li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-self_supervised_learning.png" /></p>
<h3 id="pretext-tasks">Pretext Tasks</h3>
<p>Labels are generated automatically.</p>
<h4 id="rotation">Rotation</h4>
<p>Train a classifier on randomly rotated images.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-pretext_rotation.png" /></p>
<h4 id="rearrangement">Rearrangement</h4>
<p>Train a classifier on randomly shuffled image pieces.</p>
<p>Predict the location of image pieces.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-pretext_rearrangement.png" /></p>
<h4 id="inpainting">Inpainting</h4>
<p>Mask part of the image, train a network to predict the masked area.</p>
<p>Method referencing <a href="https://arxiv.org/pdf/1604.07379.pdf">Context Encoders: Feature Learning by Inpainting</a>.</p>
<p>Combine two types of loss together to get better performance:</p>
<ol>
<li><strong>Reconstruction loss (L2 loss):</strong> Used for reconstructing global features.</li>
<li><strong>Adversarial loss:</strong> Used for generating texture features.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-pretext_inpainting.png" /></p>
<h4 id="coloring">Coloring</h4>
<p>Transfer between greyscale images and colored images.</p>
<p><strong>Cross-channel predictions for images:</strong> <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Split-Brain_Autoencoders_Unsupervised_CVPR_2017_paper.pdf">Split-Brain Autoencoders</a>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-pretext_coloring_sb_ae.png" /></p>
<p><strong>Video coloring:</strong> Establish mappings between reference and target frames in a learned feature space. <a href="https://arxiv.org/abs/1806.09594">Tracking Emerges by Colorizing Videos</a>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-pretext_coloring_video.png" /></p>
<h4 id="summary-for-pretext-tasks">Summary for Pretext Tasks</h4>
<ol>
<li>Pretext tasks focus on <strong>“visual common sense”</strong>.</li>
<li>The models are forced learn good features about natural images.</li>
<li>We <strong>don’t</strong> care about the performance of these <strong>pretext tasks</strong>. </li>
</ol>
<p>What we care is the performance of <strong>downstream tasks</strong>.</p>
<h4 id="problems-of-specific-pretext-tasks">Problems of Specific Pretext Tasks</h4>
<ol>
<li>Coming up with <strong>individual</strong> pretext tasks is tedious.</li>
<li>The learned representations may <strong>not be general</strong>.</li>
</ol>
<p><strong>Intuitive Solution:</strong> Contrastive Learning.</p>
<h3 id="contrastive-representation-learning">Contrastive Representation Learning</h3>
<p><strong>Local additional references:</strong> <a href="....\DL\Contrastive Learning\Contrastive Learning.md">Contrastive Learning.md</a>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-contrastive.png" /></p>
<p><strong>Objective:</strong></p>
<p>Given a chosen score function <span class="arithmatex">\(s\)</span>, we aim to learn an encoder function <span class="arithmatex">\(f\)</span> that yields:</p>
<ol>
<li>For each sample <span class="arithmatex">\(x\)</span>, increase the similarity <span class="arithmatex">\(s\big(f(x),f(x^+)\big)\)</span> between <span class="arithmatex">\(x\)</span> and positive samples <span class="arithmatex">\(x^+\)</span>.</li>
<li>Finally we want <span class="arithmatex">\(s\big(f(x),f(x^+)\big)\gg s\big(f(x),f(x^-)\big)\)</span>.</li>
</ol>
<p><strong>Loss Function:</strong> </p>
<p>Given <span class="arithmatex">\(1\)</span> positive sample and <span class="arithmatex">\(N-1\)</span> negative samples:</p>
<table>
<thead>
<tr>
<th>InfoNCE Loss</th>
<th>Cross Entropy Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\begin{aligned}\mathcal{L}=-\mathbb{E}_X\Bigg[\log\frac{\exp{s\big(f(x),f(x^+)\big)}}{\exp{s\big(f(x),f(x^+)\big)}+\sum_{j=1}^{N-1}\exp{s\big(f(x),f(x^+)\big)}}\Bigg]\\\end{aligned}\)</span></td>
<td><span class="arithmatex">\(\begin{aligned}\mathcal{L}&amp;=-\sum_{i=1}^Np(x_i)\log q(x_i)\\&amp;=-\mathbb{E}_X\big[\log q(x)\big]\\&amp;=-\mathbb{E}_X\Bigg[\log\frac{\exp(x)}{\sum_{j=1}^N\exp(x_j)}\Bigg]\end{aligned}\)</span></td>
</tr>
</tbody>
</table>
<p>The <em>InfoNCE Loss</em> is a lower bound on the <em>mutual information</em> between <span class="arithmatex">\(f(x)\)</span> and <span class="arithmatex">\(f(x^+)\)</span>:</p>
<p><span class="arithmatex">\(\text{MI}\big[f(x),f(x^+)\big]\ge\log(N)-\mathcal{L}\)</span></p>
<p>The <em>larger</em> the negative sample size <span class="arithmatex">\(N\)</span>, the <em>tighter</em> the bound.</p>
<p>So we use <span class="arithmatex">\(N-1\)</span> negative samples.</p>
<h4 id="instance-contrastive-learning">Instance Contrastive Learning</h4>
<h5 id="simclr"><a href="https://arxiv.org/pdf/2002.05709.pdf">SimCLR</a></h5>
<p>Use a projection function <span class="arithmatex">\(g(\cdot)\)</span> to project features to a space where contrastive learning is applied.</p>
<p>The extra projection contributes a lot to the final performance.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-contrastive_simclr_frame.jpg" /></p>
<p><strong>Score Function:</strong> Cos similarity <span class="arithmatex">\(s(u,v)=\frac{u^Tv}{||u||||v||}\\\)</span>.</p>
<p><strong>Positive Pair:</strong> Pair of augmented data.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-contrastive_simclr_algo.png" /></p>
<h5 id="momentum-contrastive-learning-moco"><a href="https://arxiv.org/pdf/1911.05722.pdf">Momentum Contrastive Learning (MoCo)</a></h5>
<p>There are mainly <span class="arithmatex">\(3\)</span> training strategy in contrastive learning:</p>
<ol>
<li><em>end-to-end:</em> Keys are updated together with queries, e.g. <strong><em>SimCLR</em></strong>.</li>
</ol>
<p><strong>(limited by GPU size)</strong></p>
<ol>
<li><em>memory bank:</em> Store last-time keys for sampling.</li>
</ol>
<p><strong>(inconsistency between <span class="arithmatex">\(q\)</span> and <span class="arithmatex">\(k\)</span>)</strong></p>
<ol>
<li><em><strong>MoCo</strong>:</em> Use momentum methods to encode keys.</li>
</ol>
<p><strong>(combination of <em>end-to-end</em> &amp; <em>memory bank</em>)</strong></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-contrastive_moco_cate.png" /></p>
<p><strong>Key differences to SimCLR:</strong></p>
<ol>
<li>Keep a running <strong>queue</strong> of keys (negative samples).</li>
<li>Compute gradients and update the encoder <strong>only through the queries</strong>.</li>
<li>Decouple min-batch size with the number of keys: can support <strong>a large number of negative samples</strong>.</li>
<li>The key encoder is <strong>slowly progressing</strong> through the momentum update rules:</li>
</ol>
<p><span class="arithmatex">\(\theta_k\leftarrow m\theta_k+(1-m)\theta_q\)</span></p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-contrastive_moco_algo.png" /></p>
<h4 id="sequence-contrastive-learning">Sequence Contrastive Learning</h4>
<h5 id="contrastive-predictive-coding-cpc">Contrastive Predictive Coding (CPC)</h5>
<p><strong>Contrastive:</strong> Contrast between “right” and “wrong” sequences using contrastive learning.</p>
<p><strong>Predictive:</strong> The model has to <em>predict</em> future patterns given the current context.</p>
<p><strong>Coding:</strong> The model learns useful <em>feature vectors</em>, or “code”, for downstream tasks, similar to other self-supervised methods.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-contrastive_cpc.png" /></p>
<h4 id="other-examples-frontier">Other Examples (Frontier)</h4>
<h5 id="contrastive-language-image-pre-training-clip">Contrastive Language Image Pre-training (CLIP)</h5>
<p>Contrastive learning between image and natural language sentences.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/14-contrastive_clip.png" /></p>
<h2 id="15-low-level-vision">15 - Low-Level Vision</h2>
<p>Pass...</p>
<h2 id="16-3d-vision">16 - 3D Vision</h2>
<h3 id="representation">Representation</h3>
<h4 id="explicit-vs-implicit">Explicit vs Implicit</h4>
<p><strong>Explicit:</strong> Easy to sample examples, hard to do inside/outside check.</p>
<p><strong>Implicit:</strong> Hard to sample examples, easy to do inside/outside check.</p>
<table>
<thead>
<tr>
<th></th>
<th>Non-parametric</th>
<th>Parametric</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Explicit</strong></td>
<td>Points.<br>Meshes.</td>
<td>Splines.<br>Subdivision Surfaces.</td>
</tr>
<tr>
<td><strong>Implicit</strong></td>
<td>Level Sets.<br>Voxels.</td>
<td>Algebraic Surfaces.<br>Constructive Solid Geometry.</td>
</tr>
</tbody>
</table>
<h4 id="point-clouds">Point Clouds</h4>
<p>The simplest representation.</p>
<p>Collection of <span class="arithmatex">\((x,y,z)\)</span> coordinates.</p>
<p><strong>Cons:</strong></p>
<ol>
<li>Difficult to draw in under-sampled regions.</li>
<li>No simplification or subdivision.</li>
<li>No direction smooth rendering.</li>
<li>No topological information.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/16-representation_point_clouds.png" /></p>
<h4 id="polygonal-meshes">Polygonal Meshes</h4>
<p>Collection of vertices <span class="arithmatex">\(v\)</span> and edges <span class="arithmatex">\(e\)</span>.</p>
<p><strong>Pros:</strong></p>
<ol>
<li>Can apply downsampling or upsampling on meshes.</li>
<li>Error decreases by <span class="arithmatex">\(O(n^2)\)</span> while meshes increase by <span class="arithmatex">\(O(n)\)</span>.</li>
<li>Can approximate arbitrary topology.</li>
<li>Efficient rendering.</li>
</ol>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/16-representation_poly.png" /></p>
<h4 id="splines">Splines</h4>
<p>Use specific functions to approximate the surface. (e.g. Bézier Curves)</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/16-representation_bezier.png" /></p>
<h4 id="algebraic-surfaces">Algebraic Surfaces</h4>
<p>Use specific functions to represent the surface.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/16-representation_algebra.png" /></p>
<h4 id="constructive-solid-geometry">Constructive Solid Geometry</h4>
<p>Combine implicit geometry with Boolean operations.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/16-representation_boolean.png" /></p>
<h4 id="level-sets">Level Sets</h4>
<p>Store a grim of values to approximate the function.</p>
<p>Surface is found where interpolated value equals to <span class="arithmatex">\(0\)</span>.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/16-representation_level_set.png" /></p>
<h4 id="voxels">Voxels</h4>
<p>Binary thresholding the volumetric grid.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WncFht/picture/main/picture/16-representation_binary.png" /></p>
<h3 id="ai-3d">AI + 3D</h3>
<p>Pass...</p>

                

  


              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
    
      <div class="md-copyright__highlight">
        Copyright © 2025 [mathcourse-share]
      </div>
    
    
      Powered by
      <a href="https://www.mkdocs.org/" target="_blank" rel="noopener">
        MkDocs
      </a>
      with theme
      <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
        Material
      </a>
      modified by
      <a href="https://github.com/WncFht" target="_blank" rel="noopener">
        WncFht
      </a>
    
</div>

    
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            


  
    
  




<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better. extra:</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="github" checked>
          <span class="task-list-indicator"></span>
          GitHub
        </label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">同意</button>
    
    
    
  
    
    
      <button type="reset" class="md-button md-button--primary">拒绝</button>
    
    
  
    
    
    
      <label class="md-button" for="__settings">管理设定</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.footnote.tooltips", "content.tabs.link", "content.tooltips", "navigation.instant"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../../javascripts/tablesort.js"></script>
      
        <script src="../../../javascripts/consent.js"></script>
      
    
  </body>
</html>